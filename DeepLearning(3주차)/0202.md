# Math for AI

- Convolution

  - MLP(Multi Layer Perceptron)과의 차이점

    <a href="https://ibb.co/wyRCwVq"><img src="https://i.ibb.co/8M02dqw/2021-02-02-18-36-18.png" alt="2021-02-02-18-36-18" border="0"></a>

    <a href="https://ibb.co/7n001Tq"><img src="https://i.ibb.co/rxXXwLV/2021-02-02-18-37-31.png" alt="2021-02-02-18-37-31" border="0"></a>

    첫 번째가 MLP 두 번째가 Convolution연산이다.

    첫 번째에서 i의 위치에 따라 가중치 행렬의 벡터를 x와 곱하여 활성 함수를 적용했으나

    두 번째 Convolution 연산에선 Kernel이란 개념이 등장하여 모든 i에 대해 적용되는

    커널은 V로 같아지고 커널의 사이즈 만큼 x상에서 이동하면서 적용한다.

    <a href="https://ibb.co/WPY8sXt"><img src="https://i.ibb.co/qWPqx85/2021-02-02-18-41-08.png" alt="2021-02-02-18-41-08" border="0"></a>

    연속과 이산의 상황에서 컨볼루션 연산 식이다. 위에서 f(x)함수가 커널에 해당하게 된다.



- 영상처리에서 Convolution

  - Convolution연산은 1차원 뿐만 아니라 다양한 차원에서 계산이 가능하다.

    <a href="https://ibb.co/VYxzdXx"><img src="https://i.ibb.co/k2JwpYJ/2021-02-02-18-42-33.png" alt="2021-02-02-18-42-33" border="0"></a>

- 2차원 Convolution 연산

  -  입력벡터 상에서 커널을 움직여가면서 선형모델과 합성함수를 적용시킨다. 

  <a href="https://ibb.co/PmphMy9"><img src="https://i.ibb.co/Gxw29Dt/2021-02-02-18-43-31.png" alt="2021-02-02-18-43-31" border="0"></a>

  

  <a href="https://ibb.co/5vcTCY2"><img src="https://i.ibb.co/hH8srXC/2021-02-02-18-44-15.png" alt="2021-02-02-18-44-15" border="0"></a>

- 3차원 Convolution 연산

  - 2차원 Convolution 연산을 3번 적용한다

    <a href="https://ibb.co/tHfnSg5"><img src="https://i.ibb.co/0nN1kT3/2021-02-02-18-45-52.png" alt="2021-02-02-18-45-52" border="0"></a>

    

    <a href="https://ibb.co/dfLLYzz"><img src="https://i.ibb.co/ZfYYDkk/2021-02-02-18-46-44.png" alt="2021-02-02-18-46-44" border="0"></a><그림 1>

    ​															

    <a href="https://ibb.co/MsNRDKT"><img src="https://i.ibb.co/t4CbMnf/2021-02-02-18-47-07.png" alt="2021-02-02-18-47-07" border="0"></a><그림 2>

    

    <그림 1>에서 커널은 1개이고 위의 커널로 3차원 입력벡터와 연산을 적용한 출력은 2차원으로 나타나게 된다. 반면 <그림 2>에서 커널을 Oc개 사용한다 가정하면 출력 역시 3차원으로 나타나게 된다.





- Convolution 연산의 역전파

  - Convolution 연산은 커널이 모든 입력데이터에 공통으로 적용되기 때문에 역전파를 계산한 결과  Convolution 연산이 나오게 된다.

    <a href="https://imgbb.com/"><img src="https://i.ibb.co/7jKFzJR/2021-02-02-18-49-50.png" alt="2021-02-02-18-49-50" border="0"></a>

    위의 수식을 그림을 예시로 들면

    <a href="https://imgbb.com/"><img src="https://i.ibb.co/ZKLzLJn/2021-02-02-18-50-32.png" alt="2021-02-02-18-50-32" border="0"></a><그림 1>

    <a href="https://ibb.co/d08TwDs"><img src="https://i.ibb.co/fYjgzHV/2021-02-02-18-51-23.png" alt="2021-02-02-18-51-23" border="0"></a><그림 2>

    

    <그림 2>에서 출력값은 입력에 커널을 적용한 값이다.

    <a href="https://ibb.co/1m2hfcB"><img src="https://i.ibb.co/MCNWDdK/2021-02-02-18-52-31.png" alt="2021-02-02-18-52-31" border="0"></a><그림 3>

    

    <그림 3>에서 입력값 중 X3 데이터는 각 커널에 적용되어 출력값에 영향을 끼치게 되었다.

    여기서 다시 역전파를 고려해 보면

    <a href="https://ibb.co/HCcDWDX"><img src="https://i.ibb.co/zF3hyhN/2021-02-02-18-53-44.png" alt="2021-02-02-18-53-44" border="0"></a>

    <그림 4>

    

    <그림 4>에서 다시 커널을 통해 그레디언트가 전달되고

    <a href="https://ibb.co/dL7LqJt"><img src="https://i.ibb.co/yYVY1Bp/2021-02-02-18-54-32.png" alt="2021-02-02-18-54-32" border="0"></a><그림 5>

    

    각 커널에 들어오는 모든 그레디언트를 더하면 결국 위와 같이 Convolution연산과 같게 된다.

    

# Optimization(최적화)

- Optimization에서의 중요한 개념

  - Generalization 

    - 학습된 모델이 예상치 못한 데이터에 얼마나 적합한지

      <a href="https://ibb.co/kcmLybh"><img src="https://i.ibb.co/rydBt8Z/2021-02-02-19-01-44.png" alt="2021-02-02-19-01-44" border="0"></a>

      

  - under-fitting vs over-fitting

    <a href="https://ibb.co/zSsc2Z3"><img src="https://i.ibb.co/VvVyCTF/2021-02-02-19-02-19.png" alt="2021-02-02-19-02-19" border="0"></a>

    가장 왼쪽은 학습이 제대로 이루어지지 않았고 가장 오른쪽은 학습이 너무 주어진 데이터에 딱 맞게 일어나 다른 테스트 셋을 적용했을 때 정확도가 떨어진다.

  - Cross validation

    - 교차 검증은 모델 유효성 검사 기법으로서,모델이 독립(테스트) 모델로 일반화된다.

      <a href="https://imgbb.com/"><img src="https://i.ibb.co/2gTfmbv/2021-02-02-19-05-23.png" alt="2021-02-02-19-05-23" border="0"></a>

      교차 검증은 데이터의 모든 부분을 사용하여 모델을 검증하고, test set을 하나로 고정하지 않는다.

    - 교차 검증의 장점

      - 장점

        - 모든 데이터 셋을 평가에 활용할 수 있다.

          - Overfitting을 방지한다.

        - 모든 데이터 셋을 훈련에 활용할 수 있다.

          - 훈련에 필요한 데이터가 부족할 경우에 교차검증을 사용하면 underfitting을 방지하게 된다.

            

  - Bias-variance tradeoff

    <a href="https://imgbb.com/"><img src="https://i.ibb.co/sCWzTJy/2021-02-02-19-07-37.png" alt="2021-02-02-19-07-37" border="0"></a>

    모델의 예측 값과 실제 데이터의 label 값의 차이를 Error라고 한다.

    Error  = variance + bias + noise로 이루어진다.

    위의 예시에서 Noise를 제외하고 생각했을 때 목표와 파란 점들이 퍼져있는 정도를 

    variance, 목표지점과 파란 점들이 떨어져 있는 정도를 bias라고 한다. 

    <a href="https://ibb.co/Zg0NG0q"><img src="https://i.ibb.co/t293Q9V/2021-02-02-19-12-28.png" alt="2021-02-02-19-12-28" border="0"></a>

    위에서 Noise는 인자를 Epsilon으로 가져 학습 시키고자 하는 모델 y와 독립적이기 때문에

    최소화가 불가능하다. 따라서 에러를 줄이기 위해서 bias나 variance를 최소화 해야하는데

    bias를 줄이면 variance가 늘어나고, variance를 줄이면 bias가 늘어나게 된다.

    

  - Bootstrapping

    - 가설 검증(test)을 하거나 메트릭(metric)을 계산하기 전에 random sampling을 적용하는 방법
    - 학습데이터가 고정되있을 때, 학습데이터를 여러개 만들어 각 데이터를 가지고 여러 모델을 만든다.
    - 교차검증과의 차이는 학습데이터를 반복해서 사용이 가능하다.

    

  - Bagging and boosting

    - Bagging (Bootstrapping aggregating)

      - 학습 데이터가 고정되있을 때, 학습데이터를 나누어 여러개로 나누고 평균(sample mean)을 구하는 것이다

    - Boosting

      - 예를들어 100개의 데이터가 있고 모델을 만들었을 때 예측이 안되는 일부의 데이터를 가지고 잘 동작하는 두 번째 모델을 만들어 기존의 모델과 합치는 것

        

# Gradient Descent Methods

- Stochastic gradient descent

  <a href="https://imgbb.com/"><img src="https://i.ibb.co/SdhnPG9/2021-02-02-19-29-00.png" alt="2021-02-02-19-29-00" border="0"></a>

  일반적인 경사 하강법

  

- Momentum

  <a href="https://imgbb.com/"><img src="https://i.ibb.co/whPhSfN/2021-02-02-19-29-58.png" alt="2021-02-02-19-29-58" border="0"></a>

  Momentum 을 사용했을 때 이동하려던 방향으로 스텝을 경사하강법 보다 더 멀리 이동하게 된다. 

  <a href="https://imgbb.com/"><img src="https://i.ibb.co/ngvnNWh/2021-02-02-19-33-56.png" alt="2021-02-02-19-33-56" border="0"></a>

  

- Nesterov accelerated gradient(NAG)

  <a href="https://imgbb.com/"><img src="https://i.ibb.co/8KR5QGT/2021-02-02-19-35-04.png" alt="2021-02-02-19-35-04" border="0"></a>

  모멘텀은 현재 주어진 파라미터에서 gradient를 계산하여 그 기울기 값과 모멘텀값을 합친 accumulation 값을 gradient로 업데이트 했지만, 반면 Nesterov accelerated gradient는 한번 이동한 후에 기울기를 계산하여 그 값과 모멘텀 값을 합하여 업데이트 한다.

  <a href="https://ibb.co/7KcFcsS"><img src="https://i.ibb.co/ZxsCsqf/2021-02-02-19-41-12.png" alt="2021-02-02-19-41-12" border="0"></a>

  Momentum 방식의 경우 멈춰야 할 시점에서도 관성에 의해 훨씬 멀리 갈수도 있다는 단점이 존재하는 반면, NAG 방식의 경우 일단 모멘텀으로 이동을 반정도 한 후 어떤 방식으로 이동해야할 지를 결정한다.

  <a href="https://imgbb.com/"><img src="https://i.ibb.co/ngvnNWh/2021-02-02-19-33-56.png" alt="2021-02-02-19-33-56" border="0"></a>

  위의 상황에서 모멘텀은 다음스텝으로 이동할 때 반대편 슬로프로 이동하고 그 다음 스텝으로 

  이동할 때 momentum으로 인해 밑으로 내려오는 것이 아닌 더 위로 올라가는 현상이 생기고 

  기울기가 최솟값으로 수렴하는데 시간이 오래 걸릴 수 있다.

  반면 Nesterov accelerated gradient는 그 상황에서 다시 내려오게 되어 최솟값으로 빠르게 수

  렴할 수 있다.

- Adagrad

  <a href="https://imgbb.com/"><img src="https://i.ibb.co/Pzv5ky8/2021-02-02-19-47-48.png" alt="2021-02-02-19-47-48" border="0"></a>

  지금까지 각 파라미터들의 변화값을 저장하여 적게  변한 파라미터는 많이 변화시키고, 많이 변한 파라미터는 적게 변화시킨다.

  만약 G가 무한대에 가까워지게 된다면 gradient값이 0이 되어 W의 업데이트가 되지 않아 

  학습을 하면 할 수록 학습이 멈춰지는 현상이 발생하게 된다.

  

- Adadelta

  <a href="https://ibb.co/Ss49j80"><img src="https://i.ibb.co/C13TcZv/2021-02-02-19-50-20.png" alt="2021-02-02-19-50-20" border="0"></a>

  G가 계속 커지는 현상을 막기 위한 방법이다. 



- RMSprop

  <a href="https://ibb.co/9WVRgQh"><img src="https://i.ibb.co/vkQ2q0h/2021-02-02-19-54-34.png" alt="2021-02-02-19-54-34" border="0"></a>

  Adagrad의 단점을 해결하기 위한 방법이다. Adagrad의 식에서 gradient의 제곱값을 더해나가면서 구한 Gt 부분을 합이 아니라 지수평균으로 바꾸어서 대체한 방법이다. 이렇게 대체를 할 경우 Adagrad처럼 Gt가 무한정 커지지는 않으면서 최근 변화량의 변수간 상대적인 크기 차이는 유지할 수 있다

- Adam

  <a href="https://ibb.co/k6nKzrj"><img src="https://i.ibb.co/cX5JRp0/2021-02-02-19-55-10.png" alt="2021-02-02-19-55-10" border="0"></a>

  Momentum 과 AdaGrad 를 융합한 방법이다. 일반적으로 가장 무난하게 gradient의 최솟값을 잘 찾는다. 

  

# Regularization(정규화)

Regularization는 학습데이터 뿐만 아니라 테스트데이터 까지 잘 동작하도록 도와주는 것

- Early stopping

  <a href="https://ibb.co/8KpsBHd"><img src="https://i.ibb.co/6nxwZk1/2021-02-02-20-00-44.png" alt="2021-02-02-20-00-44" border="0"></a>

  학습 횟수가 많을수록 학습 데이터에 관한 오차는 작아지지만 이것이 오버피팅을 초래해서 모델의 일반화 성능이 떨어지게 된다. 따라서 Early stopping은 이전 epoch 때와 비교해서 오차가 증가했다면 학습을 중단한다

- Parameter norm penalty

  <a href="https://imgbb.com/"><img src="https://i.ibb.co/N9c75Lc/2021-02-02-20-04-09.png" alt="2021-02-02-20-04-09" border="0"></a>

  <a href="https://ibb.co/2jVJ7RM"><img src="https://i.ibb.co/tbjRMn2/2021-02-02-20-17-16.png" alt="2021-02-02-20-17-16" border="0"></a>

  학습을 진행할 떄 특정 Weight의 값이 커지게 되어 overfitting 되는 현상을 방지 하기 위한 방법

  이다. L2 정규화는 제곱한 가중치 값을 더해줌으로써 편미분 을 통해 back propacation 할 때

  Cost 뿐만 아니라 가중치 또한 줄어드는 방식으로 학습을 한다.

  

- Data augmentation

  <a href="https://ibb.co/zst6hBX"><img src="https://i.ibb.co/fMTDYyk/2021-02-02-20-21-14.png" alt="2021-02-02-20-21-14" border="0"></a>

  <a href="https://imgbb.com/"><img src="https://i.ibb.co/FzFjKgG/2021-02-02-20-22-23.png" alt="2021-02-02-20-22-23" border="0"></a>

  데이터가 많으면 많을 수록 학습이 잘되기 때문에 데이터가 적을 경우 사용하게 된다.

  주로 사용하는 방법으로는 이미지 반전, 이미지 밝기 조절, 이미지 각도 변화, 노이즈 추가 등이 

  있다. 학습셋 크기를 늘리기 위해 데이터를 변환할 때, 데이터의 특징을 고려해야 한다. 

  예를 들어, 6과 9처럼 180도를 뒤집은 것과 같은 데이터의 경우에는 좌우 반전하여 데이터

  를 늘리는 것은 적절하지 않는 방법이다. 

  

- Noise robustness

  <a href="https://ibb.co/K62jkwh"><img src="https://i.ibb.co/fMkY5vF/2021-02-02-20-24-12.png" alt="2021-02-02-20-24-12" border="0"></a>

  노이즈가 낀 데이터를 테스트해도 좋은 학습 결과를 내기 위해서 학습시 일부러 노이즈가 낀 데

  이터를 추가한다. 레이어 중간에 노이즈를 추가(noise injection)하는 게 파라미터를 줄이는 것

  (L2 weight decay)보다 강력할 수 있다. 

  

- Label smoothing

  <a href="https://imgbb.com/"><img src="https://i.ibb.co/k9ZSJXT/2021-02-02-20-29-39.png" alt="2021-02-02-20-29-39" border="0"></a>

  <a href="https://imgbb.com/"><img src="https://i.ibb.co/tKtFVHB/2021-02-02-20-30-47.png" alt="2021-02-02-20-30-47" border="0"></a>

  학습 데이터 두개를 뽑아 섞는다. 위와 같은 방법을 통해 트레이닝 시키면 성능이 많이 올라가게 

  된다.

- Dropout

  <a href="https://ibb.co/b6JCmL2"><img src="https://i.ibb.co/x2HBLGf/2021-02-02-20-31-13.png" alt="2021-02-02-20-31-13" border="0"></a>

  몇개의 weight를 0으로 바꾼다. 

- Batch normalization

  <a href="https://imgbb.com/"><img src="https://i.ibb.co/hFGd2HS/2021-02-02-20-32-24.png" alt="2021-02-02-20-32-24" border="0"></a>

  배치 정규화는 활성함수의 활성화값 또는 출력값을 정규화(정규분포로 만든다)하는 작업을 말한

  다. 미니배치를 한 단위로 정규화를 하는 것으로 분포의 평균이 0, 분산이 1이 되도록 정규화한다.

  입력층의 입력 데이터는 쉽게 normalization 할 수 있지만, 입력층을 지나서 만나게 되는 layer 

  들의 입력은 normalization 하기 쉽지 않다. Batch normalization 은 이런 문제를 해결하기 위한 

  알고리즘이다. output = g(Z), Z = WX+b 가 output = g(BN(Z)), Z = WX+b 로 변경되는 것이다.

  배치 정규화를 출력에서 활성함수를 적용하기 전에 하는 것이 더 높은 성능을 나타내는지, 활성함수 적용 후에 하는 것이 더 높은 성능을 나타내는지 는 아직 정확하게 밝혀지지 않았다.

  