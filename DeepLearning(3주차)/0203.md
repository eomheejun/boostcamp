# Modern CNN

- ILSVRC(ImageNet Large-Scale Visual Recognition Challenge)

  - Classification / Detection/ Localization / Segmentation

  - 1000 다양한 카테고리 (ex)강아지,고양이,호랑이 등)

  - 100만장의 이미지

    <a href="https://imgbb.com/"><img src="https://i.ibb.co/9nk1SMK/2021-02-03-10-24-15.png" alt="2021-02-03-10-24-15" border="0"></a>

    <a href="https://ibb.co/0MCd4Z3"><img src="https://i.ibb.co/QNP1SnG/2021-02-03-10-25-31.png" alt="2021-02-03-10-25-31" border="0"></a>

    

- AlexNet

   <a href="https://imgbb.com/"><img src="https://i.ibb.co/cQv7Lxr/2021-02-03-10-31-58.png" alt="2021-02-03-10-31-58" border="0"></a>

  

  <a href="https://ibb.co/F0fZRNv"><img src="https://i.ibb.co/D86c0sX/2021-02-03-10-26-40.png" alt="2021-02-03-10-26-40" border="0"></a>

  네트워크가 2개로 나뉘는 이유는 GPU의 성능이 당시 부족하여 최대한 많은 파라미터를 넣기 위해 GPU를 하나 추가했다. 8개의 레이어로 이루어진 Neural Network이다.

  - key ideas

    - 활성함수 ReLU 사용
    - 2개의 GPU활용
    - 정규화 사용
      - Data augmentation
      - Dropout

    지금 생각하면 당연한 얘기지만 논문 발표될 때는 아니었다.



- VGGNet

  <a href="https://imgbb.com/"><img src="https://i.ibb.co/bsTNSz0/2021-02-03-10-33-42.png" alt="2021-02-03-10-33-42" border="0"></a>

  

  <a href="https://ibb.co/ZV5m6LG"><img src="https://i.ibb.co/80qcDKN/2021-02-03-10-34-08.png" alt="2021-02-03-10-34-08" border="0"></a>

  

  <a href="https://ibb.co/CbLckCN"><img src="https://i.ibb.co/1rcgDyh/2021-02-03-10-34-31.png" alt="2021-02-03-10-34-31" border="0"></a>

  3x3을 두번쓰는것이 5x5를 한번 쓰는 것보다 파라미터는 줄일 수 있다. (성능이 좋으려면 파라미터수는 줄이고 깊이는 깊게)



- GoogLeNet

  <a href="https://imgbb.com/"><img src="https://i.ibb.co/hVmhZc7/2021-02-03-10-38-12.png" alt="2021-02-03-10-38-12" border="0"></a>

  

  <a href="https://ibb.co/pKnNJ19"><img src="https://i.ibb.co/PWtJwrf/2021-02-03-10-38-36.png" alt="2021-02-03-10-38-36" border="0"></a>

  네트워크 안에 네트워크가있어 NIN 구조라고 한다.

  

  <a href="https://ibb.co/qNthvpR"><img src="https://i.ibb.co/McYKm7R/2021	-02-03-10-39-16.png" alt="2021-02-03-10-39-16" border="0"></a>

  - Inception blocks의 장점

    - 1x1 필터를 중간 중간 추가해 전체적인 파라미터수를 줄인다.

    

    

    ​		<a href="https://ibb.co/0XBTYGQ"><img src="https://i.ibb.co/b3HTNK7/2021-02-03-10-39-47.png" alt="2021-02-03-10-39-47" border="0"></a>

  ​	 

​				왼쪽의 경우 3x3 필터를 적용한 결과이고, 오른쪽은 1x1적용후 3x3필터를 적용했다.





- ResNet

  <a href="https://imgbb.com/"><img src="https://i.ibb.co/bLYcgZs/2021-02-03-10-49-27.png" alt="2021-02-03-10-49-27" border="0"></a>

  

  

  <a href="https://ibb.co/Mcphj7n"><img src="https://i.ibb.co/1rKnpTZ/2021-02-03-10-50-10.png" alt="2021-02-03-10-50-10" border="0"></a>

  일반적으로 층을 깊게 쌓게 되면 train error가 더 작고  test error가 더 크다. 네트워크가 커져도 학습이 안된다. 따라서 Layer를 깊게 쌓을 수록 성능을 좋게하는 방법을 만들기 위한 방법이다.

  

  <a href="https://ibb.co/4pMQhq6"><img src="https://i.ibb.co/0rZwH7g/2021-02-03-10-52-26.png" alt="2021-02-03-10-52-26" border="0"></a>

  따라서 위와 같은 현상을 방지하기위해 Identity map을 더해준다. 입력이 각 층을 통과하는 출력에 입력값을 더해준다. 기존의 신경망은 입력값 x를 타겟값 y로 매핑하는 함수 H(x)를 얻는 것이 목적이었다. 그러나 **ResNet은 F(x) + x를 최소화하는 것을 목적으로 한다.** x는 현시점에서 변할 수 없는 값이므로 F(x)를 0에 가깝게 만드는 것이 목적이 된다. F(x)가 0이 되면 출력과 입력이 모두 x로 같아지게 된다. F(x) = H(x) - x이므로 F(x)를 최소로 해준다는 것은 H(x) - x를 최소로 해주는 것과 동일한 의미를 지닌다. 따라서 F(x)를 학습한다는 것은 H(x)에서 입력값을 뺀 그 차이만 학습을 한다.

  

  <a href="https://ibb.co/XsWZyCH"><img src="https://i.ibb.co/6PyRvWQ/2021-02-03-10-52-44.png" alt="2021-02-03-10-52-44" border="0"></a>

  <a href="https://ibb.co/1TvZDKv"><img src="https://i.ibb.co/0rDqgZD/2021-02-03-11-03-54.png" alt="2021-02-03-11-03-54" border="0"></a>

  

  

  <a href="https://ibb.co/WtKNDkT"><img src="https://i.ibb.co/Qdm78P5/2021-02-03-11-02-29.png" alt="2021-02-03-11-02-29" border="0"></a>

  1x1 convolution을 이용해 입력값을 더해 줄때 차원을 맞춰준다.

  <a href="https://ibb.co/kmhccxn"><img src="https://i.ibb.co/41jNN7y/2021-02-03-11-05-17.png" alt="2021-02-03-11-05-17" border="0"></a>



- DenseNet

  <a href="https://imgbb.com/"><img src="https://i.ibb.co/9nz019y/2021-02-03-11-06-07.png" alt="2021-02-03-11-06-07" border="0"></a>

  DenseNet은 ResNet과 달리 입력갑을 더해주는 것이 아닌 Concatenation한다.

  <a href="https://ibb.co/YBKTS4f"><img src="https://i.ibb.co/pjsrT64/2021-02-03-11-07-03.png" alt="2021-02-03-11-07-03" border="0"></a>

  따라서 채널이 기하급수적으로 커지게 된다. 하지만 성능을 높이기 위해서는 파라미터수를 줄여야 하는데 위와 같은 경우에는 파라미터가 오히려 늘어나게 되므로 DenseNet은 중간 중간 파라미터 수를 줄이는 작업을 한다.

  

  <a href="https://ibb.co/jyVpQd6"><img src="https://i.ibb.co/ZBHZF3L/2021-02-03-11-07-42.png" alt="2021-02-03-11-07-42" border="0"></a>

  BatchNorm을 한 뒤 1x1 필터를 이용해 채널수를 줄이고 2x2 AvgPooling을 하고 이 작업을 반복한다.



- Tip

  - pooling

    <a href="https://ibb.co/6t0TGLs"><img src="https://i.ibb.co/7ptZBLy/2021-02-03-11-12-07.png" alt="2021-02-03-11-12-07" border="0"></a>





# Computer Vision Applications

- Semantic Segmentation

  - 이미지에 있는 객체를 픽셀 단위로 분류하는 것 (자율주행에서 많이 사용)

    <a href="https://imgbb.com/"><img src="https://i.ibb.co/jTxjv95/2021-02-03-11-13-15.png" alt="2021-02-03-11-13-15" border="0"></a>





- Fully Convolutional Network

  <a href="https://imgbb.com/"><img src="https://i.ibb.co/p2Bcr60/2021-02-03-11-15-19.png" alt="2021-02-03-11-15-19" border="0"></a>

  

  

  <a href="https://imgbb.com/"><img src="https://i.ibb.co/xL2q2fc/2021-02-03-11-15-48.png" alt="2021-02-03-11-15-48" border="0"></a>

  dense layer를 없애기 위해 만들어진 방법이다. 

  

  <a href="https://ibb.co/WKk3q4P"><img src="https://i.ibb.co/12rnhtd/2021-02-03-11-15-54.png" alt="2021-02-03-11-15-54" border="0"></a>

  왼쪽의 기존의 CNN과 Fully Convolutional Network의 파라미터 수는 똑같다. 그러나, 오른쪽과 같이 하는 이유는 다음과 같다.

  

  <a href="https://ibb.co/xLVms9R"><img src="https://i.ibb.co/2hX86Vf/2021-02-03-11-21-20.png" alt="2021-02-03-11-21-20" border="0"></a>

  Fully Convolutional Network의 가장 큰 장점은 입력 이미지에 상관없이 네틑워크가 작동한다.

  다시 말해 입력이미지가 굉장히 크던 작던 kernel이 동일하게 맞춰서 찍어 출력하기 때문에 잘 

  동작 할 수 있게 된다.

  

  <a href="https://ibb.co/Wy9b9LH"><img src="https://i.ibb.co/pzDtDS1/2021-02-03-11-21-53.png" alt="2021-02-03-11-21-53" border="0"></a>

  그러나 출력 dimension이 줄어들게 되어 뭉쳐있는 정보만을 대략적으로 가지고 있다. 하지만 우리의 목표는 픽셀 단위의 정확하고 세밀한 Segmentation이다. 따라서 다시 원래 입력dimension과 동일하게 늘려주어야 한다. 그 작업을 Unsampling이라고 하고 아래는 대표적인 2가지 Unsampling 방법이다.

  

  - Unpooling (Pooling layer에서 발생하는 축소에서 사용)

    - Nearest Neighbor Unpooling

      <a href="https://ibb.co/s6ssbp3"><img src="https://i.ibb.co/z7PPQWf/2021-02-03-11-39-00.png" alt="2021-02-03-11-39-00" border="0"></a>

    - Bed of Nails Unpooling

      <a href="https://ibb.co/DCQdNGk"><img src="https://i.ibb.co/gTJYGvw/2021-02-03-11-39-08.png" alt="2021-02-03-11-39-08" border="0"></a>

    - Max Unpooling

      <a href="https://ibb.co/1GSBVmT"><img src="https://i.ibb.co/k2dznSX/2021-02-03-11-39-29.png" alt="2021-02-03-11-39-29" border="0"></a>

      Bed of Nails Unpooling과의 차이점은  max pooling 된 위치를 기억하고, 그 위치에 값을 복원하여 정보 손실을 방지한다

  

  

  

  - Deconvolution(Convolution layer에서 발생하는 축소에서 사용)

    

    <a href="https://ibb.co/7QGmJNG"><img src="https://i.ibb.co/FXBTbqB/2021-02-03-11-30-21.png" alt="2021-02-03-11-30-21" border="0"></a>

    <a href="https://ibb.co/4WFpPbf">	<img src="https://i.ibb.co/5T1LBQ9/2021-02-03-11-28-23.png" alt="2021-02-03-11-28-23" border="0"></a>

    출력으로 나온 이미지를 다시 Padding과 stride를 조절하여 3x3필터링을 통해 원래의 크기와 동일하게 맞추는 작업이다.

    

    <a href="https://ibb.co/jDm20WV"><img src="https://i.ibb.co/yqt1vYh/2021-02-03-11-28-29.png" alt="2021-02-03-11-28-29" border="0"></a>

  

  

- Detection

  이미지안에서 물체가 어디있는지에 대해서 Pixel을 사용하는 것이 아닌 bounding box를 사용한다.

  - R-CNN

    <a href="https://ibb.co/b16qfyT"><img src="https://i.ibb.co/G7dBh1y/2021-02-03-11-43-47.png" alt="2021-02-03-11-43-47" border="0"></a>

    이미지 안에서 bounding box를 2000개를 뽑고 같은 크기로 맞춘 후(CNN을 사용하기 위해)에 분류를 한다.

    

    <a href="https://ibb.co/pj6wQRT"><img src="https://i.ibb.co/CKp86My/2021-02-03-11-44-49.png" alt="2021-02-03-11-44-49" border="0"></a>

    

    

  - SPPNet

    R-CNN의 가장큰 문제는 이미지 안에서 bounding box를 2000번 추출하여 2000개의 각 이미지들을 CNN을 적용해야하는데 시간이 굉장히 오래걸린다. 따라서 전체 이미지 1개에서 CNN을 2000번 적용하는데 SPPNet은 이미지 1개에 1번의 CNN을 적용하게 된다.

    

    <a href="https://ibb.co/CtnHsWr"><img src="https://i.ibb.co/rtZwfvW/2021-02-03-11-48-15.png" alt="2021-02-03-11-48-15" border="0"></a>

    이미지 안에서 bounding box를 뽑고 뽑힌 bounding box의 위치에 해당하는 tensor를 가져와 CNN을 적용하게 된다.

    

  - Fast R-CNN

    <a href="https://ibb.co/YB0cFDj"><img src="https://i.ibb.co/PGDcvTC/2021-02-03-11-52-24.png" alt="2021-02-03-11-52-24" border="0"></a>

    SPPNet에 NeuralNetwork를 추가했다.

    <a href="https://imgbb.com/">	<img src="https://i.ibb.co/3SPSTy4/2021-02-03-11-52-38.png" alt="2021-02-03-11-52-38" border="0"></a>

    

    bounding box를 추출하는 것을 학습시킨다. 따라서 R-CNN은 CNN 특징 추출부터 classification, bounding box regression 까지 하나의 모델에서 학습하게 된다.

  

  - Region Proposal Network

    <a href="https://ibb.co/fStYdLL"><img src="https://i.ibb.co/VNDWY55/2021-02-03-11-56-58.png" alt="2021-02-03-11-56-58" border="0"></a>

    이미지에서 특성 영역에 물체가 있을지 없을지 알아낸다. Anchor box는 미리 정해놓은 bounding box크기이다.

    

    <a href="https://ibb.co/p49Qf6k"><img src="https://i.ibb.co/RQVN3GJ/2021-02-03-11-57-05.png" alt="2021-02-03-11-57-05" border="0"></a>

    

    

- YOLO

  Faster R-CNN보다 훨씬 빠르다

  <a href="https://ibb.co/TDfKsft"><img src="https://i.ibb.co/wZkJfk4/2021-02-03-11-59-17.png" alt="2021-02-03-11-59-17" border="0"></a>

  bounding box를 따로 뽑을 필요없이 한번에 작업하게 된다.

  

  <a href="https://ibb.co/s5h2KJF"><img src="https://i.ibb.co/vsbH3vJ/2021-02-03-12-01-42.png" alt="2021-02-03-12-01-42" border="0"></a>

  이미지가 들어오면 S*S grid로 나누게 되고 

  <a href="https://ibb.co/SJThBBW"><img src="https://i.ibb.co/DLXxQQs/2021-02-03-12-01-46.png" alt="2021-02-03-12-01-46" border="0"></a>

  각 그리드 영역에서 먼저 물체가 있을 만한 영역에 해당하는 B개의 Bounding Box를 예측한다.이 때 bounding box는 (x, y, w, h)로 나타내어 지는데 (x, y)는 bounding box의 중심점 좌표이며 w, h는 넓이와 높이를 나타낸다. 또한 faster R-CNN에서 마지막 쓸모있는 bounding box인지 확인하는 것을 YES OR NO를 계산한다. 

  How?

  물체가 있을 확률 P(Object)와 예측한 박스와 Ground Truth 박스와의 겹치는 영역을 비율을 나타내는 IoU를 곱해서 계산한다.

  <a href="https://imgbb.com/"><img src="https://i.ibb.co/hgBWy2V/2021-02-03-12-09-05.png" alt="2021-02-03-12-09-05" border="0"></a>

  

  <a href="https://ibb.co/c1mch9z"><img src="https://i.ibb.co/Czr5Kyx/2021-02-03-12-01-51.png" alt="2021-02-03-12-01-51" border="0"></a>

  그 후에 각각의 그리드마다 C개의 클래스에 대하여 해당 클래스일 확률을 계산한다.

  <a href="https://imgbb.com/"><img src="https://i.ibb.co/F7b3cHx/2021-02-03-12-13-48.png" alt="2021-02-03-12-13-48" border="0"></a>

  

  <a href="https://ibb.co/vc8Z3gD"><img src="https://i.ibb.co/cydD6Mx/2021-02-03-12-01-57.png" alt="2021-02-03-12-01-57" border="0"></a>

  Yolo는어떤 input image가 있으면, 하나의 신경망을 통과하여 물체의 bounding box와 class를 동시에 예측하게 되어 굉장히 빠른속도로 물체를 찾게된다.



