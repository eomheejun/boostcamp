# Training & Inference

- Loss

  <a href="https://ibb.co/ZGYSNHx"><img src="https://i.ibb.co/ckCwxbQ/2021-04-02-20-57-05.png" alt="2021-04-02-20-57-05" border="0"></a>

  <a href="https://ibb.co/bRhLm1X"><img src="https://i.ibb.co/prDZw2d/2021-04-02-20-57-54.png" alt="2021-04-02-20-57-54" border="0"></a>

  목표값과 현재 예측값의 차이를 Loss로 지정 분류문제에선 주로 Cross Entropy 회귀문제에서는 MSE를 주로 쓴다. 그 외에도 다양한 Loss함수들이 있다.

  ```
  ##Cross Entropy
  
  class CrossEntropyLoss(nn.Module):
      def __init__(self, weight=None, reduction='mean'):
          nn.Module.__init__(self)
          self.weight = weight
          self.reduction = reduction
  
      def forward(self, input_tensor, target_tensor):
          log_prob = F.log_softmax(input_tensor, dim=-1)
          prob = torch.exp(log_prob)
          return F.nll_loss(
              log_prob,
              target_tensor,
              weight=self.weight,
              reduction=self.reduction
          )
  ```

  파이토치에 내장함수로 있는 Cross Entropy의 구조이다. 

  ```
  ##Focal Loss
  
  class FocalLoss(nn.Module):
      def __init__(self, weight=None,
                   gamma=2., reduction='mean'):
          nn.Module.__init__(self)
          self.weight = weight
          self.gamma = gamma
          self.reduction = reduction
  
      def forward(self, input_tensor, target_tensor):
          log_prob = F.log_softmax(input_tensor, dim=-1)
          prob = torch.exp(log_prob)
          return F.nll_loss(
              ((1 - prob) ** self.gamma) * log_prob,
              target_tensor,
              weight=self.weight,
              reduction=self.reduction
          )
  ```

  Cross Entropy와 다르게 Imbalanced Data 문제를 해결하기 위한 손실함수이다.

  ```
  ## Label Smoothing Loss
  
  class LabelSmoothingLoss(nn.Module):
      def __init__(self, classes=3, smoothing=0.0, dim=-1):
          super(LabelSmoothingLoss, self).__init__()
          self.confidence = 1.0 - smoothing
          self.smoothing = smoothing
          self.cls = classes
          self.dim = dim
  
      def forward(self, pred, target):
          pred = pred.log_softmax(dim=self.dim)
          with torch.no_grad():
              true_dist = torch.zeros_like(pred)
              true_dist.fill_(self.smoothing / (self.cls - 1))
              true_dist.scatter_(1, target.data.unsqueeze(1), self.confidence)
          return torch.mean(torch.sum(-true_dist * pred, dim=self.dim))
  ```

  Label Smoothing은 학습 데이터의 representation을 더 잘나타내는데 도움을 준다.

  ```
  ## F1 Loss
  
  class F1Loss(nn.Module):
      def __init__(self, classes=3, epsilon=1e-7):
          super().__init__()
          self.classes = classes
          self.epsilon = epsilon
      def forward(self, y_pred, y_true):
          assert y_pred.ndim == 2
          assert y_true.ndim == 1
          y_true = F.one_hot(y_true, self.classes).to(torch.float32)
          y_pred = F.softmax(y_pred, dim=1)
  
          tp = (y_true * y_pred).sum(dim=0).to(torch.float32)
          tn = ((1 - y_true) * (1 - y_pred)).sum(dim=0).to(torch.float32)
          fp = ((1 - y_true) * y_pred).sum(dim=0).to(torch.float32)
          fn = (y_true * (1 - y_pred)).sum(dim=0).to(torch.float32)
  
          precision = tp / (tp + fp + self.epsilon)
          recall = tp / (tp + fn + self.epsilon)
  
          f1 = 2 * (precision * recall) / (precision + recall + self.epsilon)
          f1 = f1.clamp(min=self.epsilon, max=1 - self.epsilon)
          return 1 - f1.mean()
  ```

  F1 Loss 는 F1점수향상을 위한 Loss함수이다.

  

- Optimizer

  <a href="https://ibb.co/0JzGv7W"><img src="https://i.ibb.co/YjVLwCK/2021-04-02-21-03-28.png" alt="2021-04-02-21-03-28" border="0"></a>

  주로 사용되는 Optimizer는 Adam, SGD가 자주 쓰인다. 어떤것이 성능이 좋을지는 직접 실험해봐야 알수가 있다.

  ```
  optimizer = optim.SGD(model.parameters(),momentum=0.9, lr = 3e-4, weight_decay= 1e-4)
  
  optimizer = optim.Adam(model.parameters(), lr = 3e-4, weight_decay= 1e-4)
  
  ```

  Optimizer를 선언한 뒤에 train에서 다음과 같이 선언해 준다.

  ```
  optimizer.zero_grad()
  loss.backward()
  optimizer.step()
  ```

  <a href="https://ibb.co/9HYPMZk"><img src="https://i.ibb.co/zVfdk6T/2021-04-02-21-05-49.png" alt="2021-04-02-21-05-49" border="0"></a>

  위와 같은 문제를 해결하기 위해  Learning rate scheduler를 사용한다.

  - StepLR

    <a href="https://ibb.co/Y7NMq1x"><img src="https://i.ibb.co/QFJR1T4/2021-04-02-21-07-02.png" alt="2021-04-02-21-07-02" border="0"></a>

  - CosineAnnealingLR

    <a href="https://ibb.co/nCdy7z7"><img src="https://i.ibb.co/hfQNBDB/2021-04-02-21-07-23.png" alt="2021-04-02-21-07-23" border="0"></a>

  - ReduceLROnPlateau

    <a href="https://ibb.co/R0Fw3BW"><img src="https://i.ibb.co/580HrnV/2021-04-02-21-07-42.png" alt="2021-04-02-21-07-42" border="0"></a>



- Metric

  <a href="https://ibb.co/fYxxDnx"><img src="https://i.ibb.co/XZCCY3C/2021-04-02-21-08-12.png" alt="2021-04-02-21-08-12" border="0"></a>

  <a href="https://ibb.co/HH3738n"><img src="https://i.ibb.co/Vq5V542/2021-04-02-21-08-48.png" alt="2021-04-02-21-08-48" border="0"></a>

  위와 같은 문제 때문에 학습후 추론과정에서 정확한 metric을 사용해야 정확도가 제대로 상승하는지 유추해 낼 수 있다.

  <a href="https://ibb.co/SdSf8jt"><img src="https://i.ibb.co/fnJD5gk/2021-04-02-21-09-29.png" alt="2021-04-02-21-09-29" border="0"></a>

  ```
  from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
  
  y_true = [0, 1, 2, 0, 1, 2]
  y_pred = [0, 2, 1, 0, 0, 1]
  
  accuracy_score(y_true, y_pred)
  
  >>
  
  0.3333333333333333
  
  precision = precision_score(y_true, y_pred, average='macro')
  
  >>
  
  0.2222222222222222
  
  recall = recall_score(y_true, y_pred, average='macro')
  
  >>
  
  0.3333333333333333
  
  f1_score(y_true, y_pred, average='macro')
  
  >>
  
  0.26666666666666666
  
  ```

  

# Training Process

<a href="https://ibb.co/27ck0Yp"><img src="https://i.ibb.co/pv4L6rk/2021-04-02-21-13-32.png" alt="2021-04-02-21-13-32" border="0"></a>

지금까지 위와 같은 과정을 겪어 최종 결과를 제출했다.

```
def train(epochs , train_loader, val_loader , model , criterion , optimizer,lr_scheduler):
    counter = 0
    best_val_acc = 0
    best_val_loss = np.inf
    patience = 5
    name = "efficient_b4"
    
    for epoch in range(epochs):
        model.train()
        
        loss_train_sum = 0
        acc_train_sum = 0
        
        for i , (img , target) in enumerate(tqdm(train_loader)):
            img = img.to(device)
            target = target.to(device, dtype=torch.int64)
            
            y_pred = model(img)
            loss = criterion(y_pred, target)
            
            optimizer.zero_grad()
            loss.backward()
            optimizer.step()

            loss_train_sum += loss
            acc_train_sum += (y_pred.argmax(1) == target).sum().item()/ 64

        loss_train_avg = loss_train_sum / len(train_loader)
        acc_train_avg = acc_train_sum / len(train_loader)
        print(f" epoch:[{epoch+1}/{epochs}] cost:[{loss_train_avg:.3f}] acc : [{acc_train_avg : .3f}]")
        
        
        model.eval()
        loss_val_sum = 0
        acc_val_sum = 0
        val_loss_items = []
        val_acc_items = []
        
        for i , (img , target) in enumerate(tqdm(val_loader)):
            img = img.to(device)
            target = target.to(device, dtype=torch.int64)
            
            with torch.no_grad():
                y_pred = model(img)
                loss = criterion(y_pred, target)
            
            loss_val_sum += loss
            acc_val_sum += (y_pred.argmax(1) == target).sum().item()/ 64
            val_loss_items.append(loss_val_sum)
            val_acc_items.append(acc_val_sum)
        
        
        loss_val_avg = loss_val_sum / len(val_loader)
        acc_val_avg = acc_val_sum / len(val_loader)
        
        if loss_val_avg < best_val_loss:
            best_val_loss = loss_val_avg
        if acc_val_avg > best_val_acc:
            print("New best model for val accuracy! saving the model..")
            best_val_acc = acc_val_avg
            counter = 0
        else:
            counter += 1
        # Callback2: patience 횟수 동안 성능 향상이 없을 경우 학습을 종료시킵니다.
        if counter > patience:
            print("Early Stopping...")
            break
            
        print(f" epoch:[{epoch+1}/{epochs}] eval_cost:[{loss_val_avg:.3f}] eval_acc : [{acc_val_avg : .3f}]")
        
        lr_scheduler.step()

```

```
train(20 , train_loader , val_loader , model, criterion ,optimizer,lr_scheduler)
```

위와 같이 train 함수를 따로 만들어 각 파라미터를 넣어 학습을 시작 했다. 학습을 시작 할때는 model.train()을 선언 해줘야 하고 학습이 끝난뒤 평가 시에는 model.eval()을 선언 해줘야 한다. 위에서 early stop 개념을 사용해줬는데 추론시 성능 향상이 없을 경우에 학습을 종료시킬 수 있다.

.

- ### Gradient Accumulation

  - Graident Accumulation은 한 iteration에 파라미터를 업데이트시키는게 아니라, gradient를 여러 iteration 동안 쌓아서 업데이트시킨다. 한 번에 파라미터를 업데이트시키는 건 noise가 있을 수 있으므로, 여러번 쌓아서 한번에 업데이트 시킴으로써 그러한 문제를 방지하기 위함이다.

    ```
    accumulation_steps = 2
    counter = 0
    best_val_acc = 0
    best_val_loss = np.inf
    for epoch in range(num_epochs):
        # train loop
        model.train()
        loss_value = 0
        matches = 0
        for idx, train_batch in enumerate(train_loader):
            inputs, labels = train_batch
            inputs = inputs.to(device)
            labels = labels.to(device)
    
            outs = model(inputs)
            preds = torch.argmax(outs, dim=-1)
            loss = criterion(outs, labels)
    
            loss.backward()
            
            # -- Gradient Accumulation
            if (idx+1) % accumulation_steps == 0:
                optimizer.step()
                optimizer.zero_grad()
    
            loss_value += loss.item()
            matches += (preds == labels).sum().item()
            if (idx + 1) % train_log_interval == 0:
                train_loss = loss_value / train_log_interval
                train_acc = matches / batch_size / train_log_interval
                current_lr = scheduler.get_last_lr()
                print(
                    f"Epoch[{epoch}/{num_epochs}]({idx + 1}/{len(train_loader)}) || "
                    f"training loss {train_loss:4.4} || training accuracy {train_acc:4.2%} || lr {current_lr}"
                )
    
                loss_value = 0
                matches = 0
    
        scheduler.step()
    
        # val loop
        with torch.no_grad():
            print("Calculating validation results...")
            model.eval()
            val_loss_items = []
            val_acc_items = []
            for val_batch in val_loader:
                inputs, labels = val_batch
                inputs = inputs.to(device)
                labels = labels.to(device)
    
                outs = model(inputs)
                preds = torch.argmax(outs, dim=-1)
    
                loss_item = criterion(outs, labels).item()
                acc_item = (labels == preds).sum().item()
                val_loss_items.append(loss_item)
                val_acc_items.append(acc_item)
    
            val_loss = np.sum(val_loss_items) / len(val_loader)
            val_acc = np.sum(val_acc_items) / len(val_set)
            
            # Callback1: validation accuracy가 향상될수록 모델을 저장합니다.
            if val_loss < best_val_loss:
                best_val_loss = val_loss
            if val_acc > best_val_acc:
                print("New best model for val accuracy! saving the model..")
                torch.save(model.state_dict(), f"results/{name}/{epoch:03}_accuracy_{val_acc:4.2%}.ckpt")
                best_val_acc = val_acc
                counter = 0
            else:
                counter += 1
            # Callback2: patience 횟수 동안 성능 향상이 없을 경우 학습을 종료시킵니다.
            if counter > patience:
                print("Early Stopping...")
                break
            
            
            print(
                f"[Val] acc : {val_acc:4.2%}, loss: {val_loss:4.2} || "
                f"best acc : {best_val_acc:4.2%}, best loss: {best_val_loss:4.2}"
            )
    ```

    위의 코드에서 학습시 한 iteration에 파라미터를 업데이틑 시키지 않고 2번에 걸쳐서 업데이트를 시켰다.

    