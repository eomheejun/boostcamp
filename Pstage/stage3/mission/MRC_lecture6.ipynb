{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "810970dc-43c8-4c66-8629-d884e0e9956a",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Value for scheme.headers does not match. Please report this to <https://github.com/pypa/pip/issues/9617>\n",
      "distutils: /opt/conda/include/python3.7m/UNKNOWN\n",
      "sysconfig: /opt/conda/include/python3.7m\u001b[0m\n",
      "\u001b[33mWARNING: Additional context:\n",
      "user = False\n",
      "home = None\n",
      "root = None\n",
      "prefix = None\u001b[0m\n",
      "Requirement already satisfied: datasets in /opt/conda/lib/python3.7/site-packages (1.4.1)\n",
      "Requirement already satisfied: pyarrow>=0.17.1 in /opt/conda/lib/python3.7/site-packages (from datasets) (3.0.0)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.7/site-packages (from datasets) (1.1.4)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.7/site-packages (from datasets) (1.18.5)\n",
      "Requirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.7/site-packages (from datasets) (2.23.0)\n",
      "Requirement already satisfied: tqdm<4.50.0,>=4.27 in /opt/conda/lib/python3.7/site-packages (from datasets) (4.41.1)\n",
      "Requirement already satisfied: dill in /opt/conda/lib/python3.7/site-packages (from datasets) (0.3.3)\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from datasets) (4.0.1)\n",
      "Requirement already satisfied: xxhash in /opt/conda/lib/python3.7/site-packages (from datasets) (2.0.2)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.7/site-packages (from datasets) (2021.4.0)\n",
      "Requirement already satisfied: multiprocess in /opt/conda/lib/python3.7/site-packages (from datasets) (0.70.11.1)\n",
      "Requirement already satisfied: huggingface-hub==0.0.2 in /opt/conda/lib/python3.7/site-packages (from datasets) (0.0.2)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from huggingface-hub==0.0.2->datasets) (3.0.12)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.0->datasets) (2020.12.5)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.0->datasets) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.0->datasets) (2.9)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.0->datasets) (1.25.8)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->datasets) (3.4.1)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->datasets) (3.7.4.3)\n",
      "Requirement already satisfied: pytz>=2017.2 in /opt/conda/lib/python3.7/site-packages (from pandas->datasets) (2020.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.7/site-packages (from pandas->datasets) (2.8.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.7/site-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.14.0)\n",
      "\u001b[33mWARNING: Value for scheme.headers does not match. Please report this to <https://github.com/pypa/pip/issues/9617>\n",
      "distutils: /opt/conda/include/python3.7m/UNKNOWN\n",
      "sysconfig: /opt/conda/include/python3.7m\u001b[0m\n",
      "\u001b[33mWARNING: Additional context:\n",
      "user = False\n",
      "home = None\n",
      "root = None\n",
      "prefix = None\u001b[0m\n",
      "\u001b[33mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[33mWARNING: Value for scheme.headers does not match. Please report this to <https://github.com/pypa/pip/issues/9617>\n",
      "distutils: /opt/conda/include/python3.7m/UNKNOWN\n",
      "sysconfig: /opt/conda/include/python3.7m\u001b[0m\n",
      "\u001b[33mWARNING: Additional context:\n",
      "user = False\n",
      "home = None\n",
      "root = None\n",
      "prefix = None\u001b[0m\n",
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.7/site-packages (4.4.1)\n",
      "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /opt/conda/lib/python3.7/site-packages (from transformers) (0.10.2)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from transformers) (2.23.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.7/site-packages (from transformers) (2021.4.4)\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from transformers) (4.0.1)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from transformers) (3.0.12)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.7/site-packages (from transformers) (4.41.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.7/site-packages (from transformers) (1.18.5)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.7/site-packages (from transformers) (20.9)\n",
      "Requirement already satisfied: sacremoses in /opt/conda/lib/python3.7/site-packages (from transformers) (0.0.45)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->transformers) (3.7.4.3)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->transformers) (3.4.1)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging->transformers) (2.4.7)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (2.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (2020.12.5)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (1.25.8)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers) (7.1.2)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers) (1.0.1)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers) (1.14.0)\n",
      "\u001b[33mWARNING: Value for scheme.headers does not match. Please report this to <https://github.com/pypa/pip/issues/9617>\n",
      "distutils: /opt/conda/include/python3.7m/UNKNOWN\n",
      "sysconfig: /opt/conda/include/python3.7m\u001b[0m\n",
      "\u001b[33mWARNING: Additional context:\n",
      "user = False\n",
      "home = None\n",
      "root = None\n",
      "prefix = None\u001b[0m\n",
      "\u001b[33mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[33mWARNING: Value for scheme.headers does not match. Please report this to <https://github.com/pypa/pip/issues/9617>\n",
      "distutils: /opt/conda/include/python3.7m/UNKNOWN\n",
      "sysconfig: /opt/conda/include/python3.7m\u001b[0m\n",
      "\u001b[33mWARNING: Additional context:\n",
      "user = False\n",
      "home = None\n",
      "root = None\n",
      "prefix = None\u001b[0m\n",
      "Collecting faiss-cpu\n",
      "  Downloading faiss_cpu-1.7.0-cp37-cp37m-manylinux2014_x86_64.whl (8.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 8.1 MB 7.9 MB/s eta 0:00:01     |█████████████████████           | 5.3 MB 1.6 MB/s eta 0:00:02     |██████████████████████▌         | 5.7 MB 1.6 MB/s eta 0:00:02\n",
      "\u001b[?25hInstalling collected packages: faiss-cpu\n",
      "\u001b[33mWARNING: Value for scheme.headers does not match. Please report this to <https://github.com/pypa/pip/issues/9617>\n",
      "distutils: /opt/conda/include/python3.7m/UNKNOWN\n",
      "sysconfig: /opt/conda/include/python3.7m\u001b[0m\n",
      "\u001b[33mWARNING: Additional context:\n",
      "user = False\n",
      "home = None\n",
      "root = None\n",
      "prefix = None\u001b[0m\n",
      "Successfully installed faiss-cpu-1.7.0\n",
      "\u001b[33mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install datasets\n",
    "!pip install transformers\n",
    "!pip install faiss-cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bec30d6f-01d1-4ee0-8e35-2a673bc83236",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm, trange\n",
    "import argparse\n",
    "import random\n",
    "from transformers import AutoTokenizer\n",
    "import numpy as np\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "import torch.nn.functional as F\n",
    "from transformers import BertModel, BertPreTrainedModel, AdamW, TrainingArguments, get_linear_schedule_with_warmup\n",
    "from torch.utils.data import (DataLoader, SequentialSampler, TensorDataset)\n",
    "\n",
    "torch.manual_seed(2021)\n",
    "torch.cuda.manual_seed(2021)\n",
    "np.random.seed(2021)\n",
    "random.seed(2021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "629b9899-322c-48df-85da-08092a0674a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset squad_kor_v1 (/opt/ml/.cache/huggingface/datasets/squad_kor_v1/squad_kor_v1/1.0.0/31982418accc53b059af090befa81e68880acc667ca5405d30ce6fa7910950a7)\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset('squad_kor_v1')\n",
    "corpus = list(set(example['context'] for example in dataset['train']))\n",
    "model_checkpoint = 'bert-base-multilingual-cased'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3429cb58-fa9d-4181-860e-52e4c8c545f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_idx = np.random.choice(range(len(dataset['train'])),128)\n",
    "training_dataset = dataset['train'][sample_idx]\n",
    "\n",
    "q_seqs = tokenizer(training_dataset['question'],padding='max_length',truncation=True,return_tensors='pt')\n",
    "p_seqs = tokenizer(training_dataset['context'],padding='max_length',truncation=True,return_tensors='pt')\n",
    "\n",
    "train_dataset = TensorDataset(p_seqs['input_ids'],p_seqs['attention_mask'],p_seqs['token_type_ids'],\n",
    "                             q_seqs['input_ids'],q_seqs['attention_mask'],q_seqs['token_type_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "81921840-6385-4054-931c-73833f450e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(args, dataset, p_model, q_model):\n",
    "    # DataLoader\n",
    "    train_sampler = RandomSampler(dataset)\n",
    "    train_dataloader = DataLoader(dataset, sampler = train_sampler, batch_size= args.per_device_train_batch_size)\n",
    "    \n",
    "    #Optimizer\n",
    "    \n",
    "    no_decay = ['bias','LayerNorm.weight']\n",
    "    optimizer_grouped_parameters = [\n",
    "        {'params':[p for n,p in p_model.named_parameters() if not any(nd in n for nd in no_decay)],'weight_decay':args.weight_decay},\n",
    "        {'params':[p for n,p in p_model.named_parameters() if any(nd in n for nd in no_decay)],'weight_decay':0.0},\n",
    "        {'params':[p for n,p in q_model.named_parameters() if not any(nd in n for nd in no_decay)],'weight_decay':args.weight_decay},\n",
    "        {'params':[p for n,p in q_model.named_parameters() if any(nd in n for nd in no_decay)],'weight_decay':0.0}\n",
    "    ]\n",
    "    optimizer = AdamW(optimizer_grouped_parameters,lr = args.learning_rate, eps=args.adam_epsilon)\n",
    "    t_total = len(train_dataloader) // args.gradient_accumulation_steps*args.num_train_epochs\n",
    "    scheduler = get_linear_schedule_with_warmup(optimizer,num_warmup_steps=args.warmup_steps,num_training_steps=t_total)\n",
    "    \n",
    "    #Bert training\n",
    "    global_step =0\n",
    "    p_model.zero_grad()\n",
    "    q_model.zero_grad()\n",
    "    \n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    train_iterator = trange(int(args.num_train_epochs),desc='Epoch')\n",
    "    for _ in train_iterator:\n",
    "        epoch_iterator = tqdm(train_dataloader,desc ='Iteration')\n",
    "        for step, batch in enumerate(epoch_iterator):\n",
    "            q_encoder.train()\n",
    "            p_encoder.train()\n",
    "            \n",
    "            if torch.cuda.is_available():\n",
    "                batch = tuple(t.cuda() for t in batch)\n",
    "                \n",
    "            p_inputs = {'input_ids':batch[0],\n",
    "                       'attention_mask':batch[1],\n",
    "                       'token_type_ids':batch[2]}\n",
    "            q_inputs = {'input_ids':batch[3],\n",
    "                       'attention_mask':batch[4],\n",
    "                       'token_type_ids':batch[5]}\n",
    "            \n",
    "            p_outputs = p_model(**p_inputs) #(batch_size,emb_dim)\n",
    "            q_outputs = q_model(**q_inputs) #(batch_size,emb_dim)\n",
    "            \n",
    "            #Calculate similarity score & loss\n",
    "            \n",
    "            sim_scores = torch.matmul(q_outputs, torch.transpose(p_outputs,0,1))\n",
    "            \n",
    "            # target\n",
    "            \n",
    "            targets = torch.arange(0,args.per_device_train_batch_size).long()\n",
    "            if torch.cuda.is_available():\n",
    "                targets=targets.to('cuda')\n",
    "                \n",
    "            sim_scores = F.log_softmax(sim_scores,dim=1)\n",
    "            loss = F.nll_loss(sim_scores,targets)\n",
    "            print(loss)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            q_model.zero_grad()\n",
    "            p_model.zero_grad()\n",
    "            global_step += 1\n",
    "            \n",
    "            torch.cuda.empty_cache()\n",
    "            \n",
    "        return p_model,q_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6d29dbff-d043-4aff-90de-92ddfba3e86c",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = TrainingArguments(\n",
    "        output_dir='dense_retireval',\n",
    "        evaluation_strategy='epoch',\n",
    "        learning_rate=2e-5,\n",
    "        per_device_train_batch_size=4,\n",
    "        per_device_eval_batch_size=4,\n",
    "        num_train_epochs=2,\n",
    "        weight_decay=0.01\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b0418940-f940-4ae7-8ae2-293a483003bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertEncoder(BertPreTrainedModel):\n",
    "    def __init__(self,config):\n",
    "        super(BertEncoder,self).__init__(config)\n",
    "        \n",
    "        self.bert = BertModel(config)\n",
    "        self.init_weights()\n",
    "        \n",
    "    def forward(self,input_ids,attention_mask=None,token_type_ids=None):\n",
    "        outputs = self.bert(input_ids,attention_mask=attention_mask,token_type_ids=token_type_ids)\n",
    "        pooled_output = outputs[1]\n",
    "        return pooled_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7ea05505-3d2a-42e2-af79-d883e21d8c2d",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertEncoder: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertEncoder from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertEncoder from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertEncoder: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertEncoder from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertEncoder from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU enabled\n"
     ]
    }
   ],
   "source": [
    "p_encoder = BertEncoder.from_pretrained(model_checkpoint)\n",
    "q_encoder = BertEncoder.from_pretrained(model_checkpoint)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    p_encoder.cuda()\n",
    "    q_encoder.cuda()\n",
    "    print('GPU enabled')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "603b9334-27ee-417c-81bf-67a94bffa1ac",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "Iteration:   0%|          | 0/32 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(21.4702, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:   3%|▎         | 1/32 [00:00<00:20,  1.49it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(9.1994, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:   6%|▋         | 2/32 [00:01<00:17,  1.67it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4.7874, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:   9%|▉         | 3/32 [00:01<00:16,  1.80it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4.4384, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  12%|█▎        | 4/32 [00:02<00:14,  1.90it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4.3410, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  16%|█▌        | 5/32 [00:02<00:13,  1.98it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(6.4740, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  19%|█▉        | 6/32 [00:02<00:12,  2.05it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(6.3254, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  22%|██▏       | 7/32 [00:03<00:11,  2.10it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(6.7213, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  25%|██▌       | 8/32 [00:03<00:11,  2.12it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.4298, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  28%|██▊       | 9/32 [00:04<00:10,  2.15it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4.4272, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  31%|███▏      | 10/32 [00:04<00:10,  2.17it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.9274, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  34%|███▍      | 11/32 [00:05<00:09,  2.18it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.4328, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  38%|███▊      | 12/32 [00:05<00:09,  2.19it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4.5354, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  41%|████      | 13/32 [00:06<00:08,  2.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(5.2171, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  44%|████▍     | 14/32 [00:06<00:08,  2.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(6.7241, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  47%|████▋     | 15/32 [00:06<00:07,  2.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(8.2334, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  50%|█████     | 16/32 [00:07<00:07,  2.19it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.1219, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  53%|█████▎    | 17/32 [00:07<00:07,  2.14it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4.0480, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  56%|█████▋    | 18/32 [00:08<00:06,  2.16it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.2670, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  59%|█████▉    | 19/32 [00:08<00:05,  2.17it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.0265, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  62%|██████▎   | 20/32 [00:09<00:05,  2.19it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.6567, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  66%|██████▌   | 21/32 [00:09<00:05,  2.19it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.1385, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  69%|██████▉   | 22/32 [00:10<00:04,  2.21it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.9358, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  72%|███████▏  | 23/32 [00:10<00:04,  2.21it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.9041, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  75%|███████▌  | 24/32 [00:11<00:03,  2.21it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.9042, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  78%|███████▊  | 25/32 [00:11<00:03,  2.21it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.0585, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  81%|████████▏ | 26/32 [00:12<00:02,  2.21it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.1286, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  84%|████████▍ | 27/32 [00:12<00:02,  2.22it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.2007, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  88%|████████▊ | 28/32 [00:12<00:01,  2.21it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.9936, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  91%|█████████ | 29/32 [00:13<00:01,  2.21it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.4152, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  94%|█████████▍| 30/32 [00:13<00:00,  2.21it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.5581, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  97%|█████████▋| 31/32 [00:14<00:00,  2.21it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.7951, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration: 100%|██████████| 32/32 [00:14<00:00,  2.17it/s]\u001b[A\n"
     ]
    }
   ],
   "source": [
    "p_encoder,q_encoder = train(args,train_dataset,p_encoder,q_encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f62d456e-0ea7-41b4-b511-008c8f72dab7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "960"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_corpus = list(set(example['context'] for example in dataset['validation']))\n",
    "len(search_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f4f67fb5-84c1-4d79-8635-058978e2b741",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 480/480 [00:11<00:00, 40.53it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(960, 768)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_p_seqs = tokenizer(search_corpus,padding='max_length',truncation=True, return_tensors='pt')\n",
    "valid_dataset = TensorDataset(valid_p_seqs['input_ids'],valid_p_seqs['attention_mask'],valid_p_seqs['token_type_ids'])\n",
    "valid_sampler = SequentialSampler(valid_dataset)\n",
    "valid_dataloader = DataLoader(valid_dataset, sampler=valid_sampler,batch_size=2)\n",
    "\n",
    "p_embs = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    \n",
    "    epoch_iterator = tqdm(valid_dataloader,desc='Iteration',position=0,leave=True)\n",
    "    p_encoder.eval()\n",
    "\n",
    "    for _,batch in enumerate(epoch_iterator):\n",
    "        batch=tuple(t.cuda() for t in batch)\n",
    "        p_inputs = {'input_ids':batch[0],\n",
    "                   'attention_mask':batch[1],\n",
    "                   'token_type_ids':batch[2]}\n",
    "        outputs = p_encoder(**p_inputs).to('cpu').numpy()\n",
    "        p_embs.extend(outputs)\n",
    "        \n",
    "p_embs = np.array(p_embs)\n",
    "p_embs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "aee58171-540e-4cf2-9bf7-d07eaa3eaa27",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_idx = np.random.choice(range(len(dataset['validation'])),5)\n",
    "query = dataset['validation'][sample_idx]['question']\n",
    "ground_truth = dataset['validation'][sample_idx]['context']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cce85c09-39bb-4362-bd9e-162453c72476",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['흥신학원 측의 기부종용에 교사들이 불법성 여부를 질의한 기관은?',\n",
       " '손석희가 미국 유학 뒤 앵커로 복직한 프로그램 이름은?',\n",
       " '나경원 의원의 비서로 중학생에 대한 막말과 협박으로 논란이 된 인물은?',\n",
       " '바이오쇼크가 최고의 엑스박스 360게임에 뽑힌 연도는?',\n",
       " '임시광고경영관리방법은 어느 규정에 속하는가?']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "46649f00-b1d9-4150-915d-f5d50205f988",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 768)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_q_seqs = tokenizer(query,padding='max_length',truncation=True, return_tensors='pt').to('cuda')\n",
    "\n",
    "with torch.no_grad():\n",
    "    q_encoder.eval()\n",
    "    q_embs = q_encoder(**valid_q_seqs).to('cpu').numpy()\n",
    "    \n",
    "torch.cuda.empty_cache()\n",
    "q_embs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "34afa316-1361-4d13-9e95-c92cef22a53e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    p_embs_cuda = torch.Tensor(p_embs).to('cuda')\n",
    "    q_embs_cuda = torch.Tensor(q_embs).to('cuda')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ad895396-d879-4f76-be70-13bd65e314fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[688,  37,   1,  ..., 330, 695, 349],\n",
      "        [688,  37, 346,  ..., 950, 695, 349],\n",
      "        [390, 522, 954,  ..., 743, 204, 360],\n",
      "        [ 37,   1, 688,  ..., 437, 695, 349],\n",
      "        [  1, 688, 486,  ..., 690, 437, 349]], device='cuda:0')\n",
      "---------0.0031676292419433594 second\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "dot_prod_scores = torch.matmul(q_embs_cuda, torch.transpose(p_embs_cuda,0,1))\n",
    "\n",
    "rank = torch.argsort(dot_prod_scores,dim=1,descending=True).squeeze()\n",
    "\n",
    "print(rank)\n",
    "\n",
    "print('---------%s second' % (time.time()-start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "79a30ee5-c1a8-4a5a-b52c-b85a1e3e3b3e",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search query 흥신학원 측의 기부종용에 교사들이 불법성 여부를 질의한 기관은? \n",
      "\n",
      "ground truth passage\n",
      "이후 오마이뉴스는 나경원이 중앙선거관리위원회에 제출한 2004년 정치자금 수입명세서를 입수해 확인한 결과 거기에 일부 기부자의 직업이 교원으로 표시되어 있다는 사실과 해당 교원들의 전화번호가 흥신학원 소속 학교의 국번과 일치한다는 점을 확인했다고 보도했다. 오마이뉴스는 또한 2004년 당시 흥신학원 재단 소속 학교에 근무하던 교사들로부터 학교측의 기부 종용이 있었다는 증언도 나왔다고 보도했다. 이때 여러 교사들이 나경원 의원에게 정치후원금을 냈는데, 일부 교사들은 교사의 정치후원금은 불법이라고 알고 있었기 때문에 교육부에 질의를 했고 이에 대해 교과부는 초중등교원은 정치기부행위를 할 수 없다는 내용의 회신을 보내왔다. 이처럼 일개 교사도 정치후원금을 내는 것이 불법이라는 사실을 알고 있었는데 판사출신인 나경원 의원이 불법인줄 몰랐겠냐는 의혹을 제기하였다. 한편, 나경원은 2011년 10월 20일 KBS라디오와의 인터뷰에서는 2004년 당시에는 공무원들도 선거 정치자금을 내는 것이 금지되지 않았었다고 주장했다. 하지만 오마이뉴스가 교과부에 확인한 바에 의하면 이는 사실과 다르다고 한다. 교과부 교원복무 담당자는 전화통화에서 교원의 정치자금 기부를 금지하는 규정은 1949년 제정된 이래 바뀐 적이 없었고 따라서 교사의 정치자금 기부가 합법이었던 적은 없었다고 밝혔다. \n",
      "\n",
      "top-1 passage with score 28.2475\n",
      "1980년 봄, 그는 김대중, 김종필 등과 대권을 놓고 경쟁하였다. 그는 전두환과 신군부의 쿠데타를 그리 걱정하지 않았고, 결국 5·17 쿠데타로 좌절되었다. 1980년 5월 17일 오전 10시, 김영삼은 신군부 군인들에 의해 가택연금을 당했다. 김영삼은 5월 20일 상도동 자택에서 5.17 비상계엄 확대 조치를 내린 신군부를 규탄하는 기자회견을 열었다. 그는 \"오늘 계엄통치를 확대 강화한 5 ·17 사태를, 민주회복이라는 국민적 목표를 배신한 폭거로 규정한다. 계엄당국의 강압통치로 빚어진 유혈사태는 이 나라를 파국으로 몰아가고있다.\"면서 '국민적 목표를 배신한 5·17 폭거'라는 기자회견문을 발표했다. 이로 인해 김영삼은 신군부에 의해 5월 20일부터 가택연금 상태에 놓이게 되었다.\n",
      "top-2 passage with score 28.1791\n",
      "2000년 5월 닌텐도는 《금·은》의 북미 공식 발매일을 그해 10월 16일로 발표하였다. 닌텐도는 8월부터 게임의 예약 판매를 시작하였으며, 예약 구매한 소비자를 대상으로 미디어 브라우저가 개발한 포켓몬 테마의 웹 브라우저가 포함된 CD-ROM을 증정한다고 밝혔다. 이 웹 브라우저는 포켓몬 종류와 포켓몬 사이트 링크를 표시하는 것이 특징이다. 애플리케이션은 포켓몬 공식 웹사이트에서 다운로드할 수 있었다. 게임은 대략 600,000장이 두 달 만에 예약 판매되면서 《포켓몬스터 피카츄》가 세운 150,000장의 기록을 갱신하였다. 발매일이 다가오면서 일렉트로닉스 부티크와 같은 소매 상점이 10월 16일보다 빨리 출하된 게임을 수령하였다고 알렸으며, 예약 구매자들에게 먼저 제공한 후 나머지를 즉시 판매하기 시작하였다. 게임은 공식 발매일보다 빠른 10월 11일부터 구할 수 있었다.\n",
      "top-3 passage with score 27.9581\n",
      "비평가들의 평가는 주로 긍정적이었으며, 게임플레이의 길이 연장과 새로운 특징 같은 가치있는 추가 요소가 게임을 전작처럼 흥미롭게 만들어주었다는 평가가 많았다. IGN의 크레이그 해리스는 게임에 \"권위적\"(masterful) 등급인 10점 만점에 10점을 주며 다음과 같이 말했다. \"《포켓몬스터 금·은》은 굉장했던 전작의 게임플레이 요소와 특징을 엄청나게 능가한다. 게임에 설계된 세세한 추가 요소들은 목록으로도 만들 수 없을 정도로 수없이 많다.\" 게임스팟의 프랭크 포보는 혁신적인 내부 시계 시스템을 칭찬하며, \"포켓몬스터 금·은의 첫 번째로 주요한 추가 요소는 시간의 표현이다. 단순한 요소처럼 느낄 수도 있겠지만, 이 시계의 추가는 게임의 다양성을 상당히 늘렸다.\"라고 평하였다. 포보는 \"대단한\"(great) 등급인 8.8점을 주었다. 닌텐도 파워는 《금·은》을 게임보이/게임보이 컬러 비디오 게임 6위로 선정하고, 새로운 포켓몬과 새로운 요소, 풀컬러 그래픽에 대해서 호평하였다.\n",
      "top-4 passage with score 27.9034\n",
      "그리고 30대에 접어든 그녀는 미야케 미유키의 소설을 기반으로 한 2012년 영화 《화차》에서 과거에서 도망치기 위해 발버둥치며 늘 불안함에 사는 차경선 역을 연기했다. 이 작품으로 김민희는 한층 성숙하고 뛰어난 연기력으로 일약 영화계의 주목을 받기 시작했고, 국내 영화감독과 평론가들에게 ‘연기 잘하는 배우’로 재평가 받게 된다. 청룡영화상 여우주연상, 백상예술대상 영화부문 여자 최우수연기상 후보에 올랐으며, 부일영화상에서 여우주연상을 수상하였다. 김민희는 그동안 꼬리표처럼 따라오던 ‘모델 출신 연기 못하는 배우’에서 ‘노력하는 김민희’ 그리고 ‘김민희의 재발견’ 등 다양한 수식어들로 불리었다. 그리고 이듬해 2013년, 노덕 감독의 로맨스 영화 《연애의 온도》에서 이민기와 함께 주연을 맡아 이전의 패셔니스타의 모습은 전혀 없는, 염색을 한 지 한참 지나서 검은 머리가 올라와 있는 헤어스타일의 평범한 은행직원 장영 역을 연기하였고, 이 영화를 통해 다시 한 번 김민희만의 자연스러운 생활연기를 보여주었다. 그녀는 청룡영화상, 부일영화상 여우주연상 후보에 올랐으며, 백상예술대상 영화부문 여자 최우수연기상과 올해의 여성영화인상 연기상을 받으며 평단의 호평을 받으며, 출연한 영화 역시 관객 수 186만 명이라는 좋은 성적을 냈다.\n",
      "top-5 passage with score 27.7799\n",
      "1947년 12월 26일, 증인석에 선 도조 히데키는 “천황에게는 책임이 없다”면서 “일본의 정치는 메이지 헌법 체제를 끝까지 준수했다”며 일본 정부와 쇼와 천황을 두둔하고 나섰다. 하지만 기도 고이치의 변호인인 윌리엄 로건이 도고 시게노리를 심문하는 과정에서 도고 시게노리는 로건의 “평화를 바라는 천황의 의사에 반해 기도 고이치가 어떠한 행동을 취한 적이 있는가”라는 질문에 “그런 적은 없다. 대일본 제국의 신민이 천황 폐하의 의사를 거역한다는 것은 있을 수 없는 일이다. 하물며 제국의 고관이라면 더욱 그러하다”라는 증언을 하면서 여태껏 변호인들과 GHQ, 일본 정부가 계획해온 ‘천황에게 책임을 지우지 않는 것’을 뒤엎게 됐다. 바로 다음인 1948년 1월 6일에 증인석에 섰을 때 도고는 이 증언을 번복하려 했다.\n"
     ]
    }
   ],
   "source": [
    "k = 5\n",
    "for i, q in enumerate(query[:1]):\n",
    "    print('Search query',q,'\\n')\n",
    "    print('ground truth passage')\n",
    "    print(ground_truth[i],'\\n')\n",
    "    \n",
    "    r = rank[i]\n",
    "\n",
    "    for j in range(k):\n",
    "        print(\"top-%d passage with score %.4f\" % (j+1,dot_prod_scores[i][r[j]]))\n",
    "        print(search_corpus[r[j]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "591fac66-3dc5-4ec1-875c-a6120182f310",
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "\n",
    "num_clusters = 16\n",
    "niter =5\n",
    "k = 5\n",
    "\n",
    "emb_dim = p_embs.shape[-1]\n",
    "index_flat = faiss.IndexFlatL2(emb_dim)\n",
    "\n",
    "clus = faiss.Clustering(emb_dim,num_clusters)\n",
    "clus.verbose = True\n",
    "clus.niter=niter\n",
    "clus.train(p_embs,index_flat)\n",
    "\n",
    "centroids = faiss.vector_float_to_array(clus.centroids)\n",
    "centroids = centroids.reshape(num_clusters,emb_dim)\n",
    "\n",
    "quantizer = faiss.IndexFlatL2(emb_dim)\n",
    "quantizer.add(centroids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1b99b5ff-750f-49bd-a22c-dc15a51f95c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "indexer = faiss.IndexIVFScalarQuantizer(quantizer, quantizer.d, quantizer.ntotal, faiss.METRIC_L2)\n",
    "indexer.train(p_embs)\n",
    "indexer.add(p_embs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2d3ac378-57b1-44dc-adba-2f3d41e3c8a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------0.0031926631927490234 seconds---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "D,I = indexer.search(q_embs,k)\n",
    "\n",
    "print('------------%s seconds---' % (time.time()-start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "283518a2-ce55-4387-aa37-fb2129cdf320",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--distance--\n",
      "[[16.545177 16.620083 17.717316 17.736902 18.45747 ]\n",
      " [13.102026 13.667351 14.499323 14.800053 14.920881]\n",
      " [19.582127 20.353817 21.163902 21.78476  21.880838]\n",
      " [15.566828 16.145767 17.03789  17.187622 17.29128 ]\n",
      " [23.740076 24.322138 25.140816 25.427517 25.784266]]\n",
      "\n",
      "\n",
      "index of top 5 passage\n",
      "[[606 886 950 927  57]\n",
      " [606 886 950 927  57]\n",
      " [606 886 950  57 927]\n",
      " [606 886 950  57 927]\n",
      " [606 886 950 927  57]]\n"
     ]
    }
   ],
   "source": [
    "print('--distance--')\n",
    "print(D)\n",
    "print('\\n')\n",
    "print('index of top 5 passage')\n",
    "print(I)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e3f4b9e5-e498-422a-8e86-7da43ec699cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search query 흥신학원 측의 기부종용에 교사들이 불법성 여부를 질의한 기관은? \n",
      "\n",
      "ground truth passage\n",
      "이후 오마이뉴스는 나경원이 중앙선거관리위원회에 제출한 2004년 정치자금 수입명세서를 입수해 확인한 결과 거기에 일부 기부자의 직업이 교원으로 표시되어 있다는 사실과 해당 교원들의 전화번호가 흥신학원 소속 학교의 국번과 일치한다는 점을 확인했다고 보도했다. 오마이뉴스는 또한 2004년 당시 흥신학원 재단 소속 학교에 근무하던 교사들로부터 학교측의 기부 종용이 있었다는 증언도 나왔다고 보도했다. 이때 여러 교사들이 나경원 의원에게 정치후원금을 냈는데, 일부 교사들은 교사의 정치후원금은 불법이라고 알고 있었기 때문에 교육부에 질의를 했고 이에 대해 교과부는 초중등교원은 정치기부행위를 할 수 없다는 내용의 회신을 보내왔다. 이처럼 일개 교사도 정치후원금을 내는 것이 불법이라는 사실을 알고 있었는데 판사출신인 나경원 의원이 불법인줄 몰랐겠냐는 의혹을 제기하였다. 한편, 나경원은 2011년 10월 20일 KBS라디오와의 인터뷰에서는 2004년 당시에는 공무원들도 선거 정치자금을 내는 것이 금지되지 않았었다고 주장했다. 하지만 오마이뉴스가 교과부에 확인한 바에 의하면 이는 사실과 다르다고 한다. 교과부 교원복무 담당자는 전화통화에서 교원의 정치자금 기부를 금지하는 규정은 1949년 제정된 이래 바뀐 적이 없었고 따라서 교사의 정치자금 기부가 합법이었던 적은 없었다고 밝혔다. \n",
      "\n",
      "top-1 passage with score 16.5452\n",
      "빅히트 엔터테인먼트의 대표이자 프로듀서인 방시혁은 2010년 9월 2일, 힙합 그룹 방탄소년단의 새 멤버를 모집하는 전국 오디션을 개최한다고 밝혔다. 이 오디션은 포털사이트 다음과 함께 ‘힛잇(HIT IT)’이라는 타이틀로 진행 되었다. 이미 방탄소년단의 멤버로 발탁된 김남준에 대해 방시혁은 “언더 힙합신에서도 실력을 인정받은 고등학생 래퍼로 랩 메이킹에 탁월하며 프로 못지 않은 실력을 지니고 있다”고 소개했다. 연습생 시절에는 임정희와 2AM 등의 회사 선배 가수들의 앨범에 참여하기도 했다. 방시혁의 진두지휘 아래 리더 RM을 중심으로 슈가, 진, 제이홉, 지민, 뷔, 정국의 랩, 보컬, 춤에 능한 7명의 최종 멤버가 발탁 되었고, 3년간의 연습시간을 보내며 힙합 아이돌 그룹으로 데뷔 준비를 마쳤다. 방탄소년단은 데뷔 전부터 자신들이 운영하는 블로그에 믹스테잎, 영상, 사진 등을 올리며 팬들과 소통해 왔다.\n",
      "top-2 passage with score 16.6201\n",
      "숙희가 히데코를 돌보면서 둘은 서로에게 묘한 설렘과 긴장을 느끼고, 숙희는 순진한 히데코에게 진심이 담긴 말들을 건넨다. 며칠 후 후지와라 백작이 저택에 방문하여 히데코의 그림 교습을 시작한다. 후지와라의 계획에 따라 히데코는 점점 그와 사랑에 빠지게 되고, 진상을 알고 있는 숙희는 그런 아가씨를 가엾게 여긴다. 히데코는 숙희가 자신의 감정을 속이고 히데코가 백작과 사랑에 빠지게 될 것이라는 말에 화가 나 그녀의 뺨을 때린다. 백작이 청혼을 한 날 밤, 히데코는 악몽을 꿀 것 같아 숙희를 방으로 부르고 첫날 밤에 무엇을 해야 할 지 모르겠다고 말한다. 숙희는 답답한 마음에 히데코를 가르치고자 입맞춤을 시작으로 직접 애무를 하고, 함께 성적인 흥분에 빠져 커닐링구스를 한다.\n",
      "top-3 passage with score 17.7173\n",
      "마리 앙투아네트(프랑스어: Marie Antoinette d'Autriche, 1755년 11월 2일 ~ 1793년 10월 16일)는 프랑스왕 루이 16세의 왕비이다. 신성로마제국 황제 프란츠 1세와 오스트리아 제국의 여제 마리아 테레지아 사이에서 막내딸로 태어났으며, 결혼 전의 이름은 마리아 안토니아 요제파 요한나 폰 외스터라이히로트링겐(독일어: Maria Antonia Josepha Johanna von Österreich-Lothringen)이며, 결혼한 후의 이름은 마리 앙투아네트 조제프 잔 도트리슈로렌(프랑스어: Marie Antoinette Josèphe Jeanne D'Autriche-Lorraine)이다. 오스트리아와 오랜 숙적이었던 프랑스와의 동맹을 위해 루이 16세와 정략결혼을 했으나 왕비로 재위하는 동안 프랑스 혁명이 일어나 38살 생일을 2주 앞두고 단두대에서 처형되었다.\n",
      "top-4 passage with score 17.7369\n",
      "게임은 1960년 랩쳐가 붕괴된 직후 잭(게임의 주인공)이 탄 비행기가 대서양을 지나는 중 불시착하는 것으로 시작한다. 추락 후에, 잭은 이 참사에서 살아남은 사람은 자신밖에 없음을 알게 되고, 가까운 곳에 등대가 설치된 섬을 발견하고 수영해 간다. 그 곳에는 수중 도시인 랩쳐로 들어가기 위한 구형 잠수기가 설치되어 있었다. 아일랜드 사람이라고 밝힌 아틀라스는 잠수함에 있는 무전기로 잭을 안전하게 인도한다. 그러는 동안 라이언은 잭을 육지 국가에서 온 요원으로 믿고 랩쳐의 자동화 시스템과 그의 페로몬으로 조정하는 스플라이서를 이용해 공격하게 한다. 아틀라스는 잭에게 살 수 있는 유일한 방법은 플라스미드로부터 받은 능력을 이용하고, ADAM을 추출하기 위해 반드시 리틀 시스터를 죽여야 한다고 말한다. 아틀라스의 말을 우연히 들은 테넌바움 박사는 잭에게 리틀 시스터를 살려야 한다고 강하게 주장하며, 각각의 리틀 시스터가 깊숙히 갖고 있던 바다 달팽이를 바꿔 플라스미드로 줄 거라고 말한다. 아틀라스는 그의 아내와 자식들이 잠수함에 숨어 있다고 하며 잭을 잠수함으로 인도한다. 잭과 아틀라스가 잠수함이 있는 만(灣)에 도착하는데 그때 라이언이 그것을 파괴시킨다. 분노한 아틀라스는 잭에게 라이언을 죽여달라고 요청한다.\n",
      "top-5 passage with score 18.4575\n",
      "블루스 선법이 다른 것도 실은 여기서 비롯되었다고 할 수 있다. 억압받는 사람의 소리이기에 거기엔 '저항의 요소'가 내재해 있다. 분위기와 자극이 가해지면 일시에 분출하고야 마는 폭발성이 있다. 말 그대로 '휴화산'이다. 초창기 백인 주인들이 드럼을 금지시켰던 이유가 바로 여기 있다. 흑인 노예들은 자신들의 고향인 아프리카에서 타악기의 비트에 맞춰 노래하고 춤추는 전통을 지녔기에, 이를 그냥 내버려두면 종족적 통일성이 고무되고 나아가서는 백인 주인들에 대한 반항과 폭동을 일으킬 불상사의 소지가 있었기 때문이었다. 백인들은 드럼을 금지시키는 대신, 내키는 대로 노래하는 흑인들에게 순종을 유도하기 위한 목적에서 유럽 스타일의 음악을 가르쳐주었다. 오늘날 가장 기본이 되는 12마디 가사 구성의 블루스 구조는 4/4박자의 일반적인 12마디 하모닉 진행이라 볼 수 있다. 12마디 블루스에서 코드 조합은 대개 3가지의 다른 코드를 사용하여 12마디를 연주한다. 그당시 사람들이 코드에 로마 숫자를 매겨 음도를 표시했는데, 예를 들어 C키 기준으로 C는 토닉 코드 (I, 1도), F는 서브도미넌트 (IV, 4도), G는 도미넌트 (V, 5도)라 한다. 진행상 마지막 코드인 도미넌트 (V, 5도)는 턴어라운드, 즉 다음 진행의 처음으로 가기위한 발판으로 쓰일수 있다. 이러한 방법은 일반적으로 10번째 마디의 마지막 박자(1마디 4박자 기준으로 4번째), 혹은 11번째 마디의 첫박자(1마디 4박자 기준으로 1번째) 쓰인다. 다른 방법으론\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, q in enumerate(query[:1]):\n",
    "    print('Search query',q,'\\n')\n",
    "    print('ground truth passage')\n",
    "    print(ground_truth[i],'\\n')\n",
    "    \n",
    "    d = D[i]\n",
    "    i = I[i]\n",
    "\n",
    "    for j in range(k):\n",
    "        print(\"top-%d passage with score %.4f\" % (j+1,d[j]))\n",
    "        print(search_corpus[i[j]])\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95359f1d-5c5c-4b26-a9b1-478a0cd5ddb0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
