{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9aac3792-531d-481b-89ab-fa44162c399b",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Value for scheme.headers does not match. Please report this to <https://github.com/pypa/pip/issues/9617>\n",
      "distutils: /opt/conda/include/python3.7m/UNKNOWN\n",
      "sysconfig: /opt/conda/include/python3.7m\u001b[0m\n",
      "\u001b[33mWARNING: Additional context:\n",
      "user = False\n",
      "home = None\n",
      "root = None\n",
      "prefix = None\u001b[0m\n",
      "Requirement already satisfied: datasets in /opt/conda/lib/python3.7/site-packages (1.4.1)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.7/site-packages (from datasets) (2021.4.0)\n",
      "Requirement already satisfied: pyarrow>=0.17.1 in /opt/conda/lib/python3.7/site-packages (from datasets) (3.0.0)\n",
      "Requirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.7/site-packages (from datasets) (2.23.0)\n",
      "Requirement already satisfied: huggingface-hub==0.0.2 in /opt/conda/lib/python3.7/site-packages (from datasets) (0.0.2)\n",
      "Requirement already satisfied: multiprocess in /opt/conda/lib/python3.7/site-packages (from datasets) (0.70.11.1)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.7/site-packages (from datasets) (1.1.4)\n",
      "Requirement already satisfied: dill in /opt/conda/lib/python3.7/site-packages (from datasets) (0.3.3)\n",
      "Requirement already satisfied: tqdm<4.50.0,>=4.27 in /opt/conda/lib/python3.7/site-packages (from datasets) (4.41.1)\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from datasets) (4.0.1)\n",
      "Requirement already satisfied: xxhash in /opt/conda/lib/python3.7/site-packages (from datasets) (2.0.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.7/site-packages (from datasets) (1.18.5)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from huggingface-hub==0.0.2->datasets) (3.0.12)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.0->datasets) (2.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.0->datasets) (2020.12.5)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.0->datasets) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.0->datasets) (1.25.8)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->datasets) (3.4.1)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->datasets) (3.7.4.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.7/site-packages (from pandas->datasets) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in /opt/conda/lib/python3.7/site-packages (from pandas->datasets) (2020.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.7/site-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.14.0)\n",
      "\u001b[33mWARNING: Value for scheme.headers does not match. Please report this to <https://github.com/pypa/pip/issues/9617>\n",
      "distutils: /opt/conda/include/python3.7m/UNKNOWN\n",
      "sysconfig: /opt/conda/include/python3.7m\u001b[0m\n",
      "\u001b[33mWARNING: Additional context:\n",
      "user = False\n",
      "home = None\n",
      "root = None\n",
      "prefix = None\u001b[0m\n",
      "\u001b[33mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[33mWARNING: Value for scheme.headers does not match. Please report this to <https://github.com/pypa/pip/issues/9617>\n",
      "distutils: /opt/conda/include/python3.7m/UNKNOWN\n",
      "sysconfig: /opt/conda/include/python3.7m\u001b[0m\n",
      "\u001b[33mWARNING: Additional context:\n",
      "user = False\n",
      "home = None\n",
      "root = None\n",
      "prefix = None\u001b[0m\n",
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.7/site-packages (4.4.1)\n",
      "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /opt/conda/lib/python3.7/site-packages (from transformers) (0.10.2)\n",
      "Requirement already satisfied: sacremoses in /opt/conda/lib/python3.7/site-packages (from transformers) (0.0.45)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from transformers) (2.23.0)\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from transformers) (4.0.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.7/site-packages (from transformers) (1.18.5)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.7/site-packages (from transformers) (4.41.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.7/site-packages (from transformers) (2021.4.4)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.7/site-packages (from transformers) (20.9)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from transformers) (3.0.12)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->transformers) (3.7.4.3)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->transformers) (3.4.1)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging->transformers) (2.4.7)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (2020.12.5)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (2.9)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (1.25.8)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers) (1.14.0)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers) (1.0.1)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers) (7.1.2)\n",
      "\u001b[33mWARNING: Value for scheme.headers does not match. Please report this to <https://github.com/pypa/pip/issues/9617>\n",
      "distutils: /opt/conda/include/python3.7m/UNKNOWN\n",
      "sysconfig: /opt/conda/include/python3.7m\u001b[0m\n",
      "\u001b[33mWARNING: Additional context:\n",
      "user = False\n",
      "home = None\n",
      "root = None\n",
      "prefix = None\u001b[0m\n",
      "\u001b[33mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install datasets\n",
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d094c3c2-9855-41ac-ac4c-12a3e12abd3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset squad_kor_v1 (/opt/ml/.cache/huggingface/datasets/squad_kor_v1/squad_kor_v1/1.0.0/31982418accc53b059af090befa81e68880acc667ca5405d30ce6fa7910950a7)\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "dataset = load_dataset('squad_kor_v1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1f35e5a5-0514-48ba-af96-054962698d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "import numpy as np\n",
    "\n",
    "model_checkpoint = 'bert-base-multilingual-cased'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "040d2894-fb23-4ac4-999e-b878a3caae56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PreTrainedTokenizerFast(name_or_path='bert-base-multilingual-cased', vocab_size=119547, model_max_len=512, is_fast=True, padding_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d1291620-5bbf-4a59-b958-41be5d915738",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_input = tokenizer(dataset['train'][0]['context'],padding='max_length',truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f9e80352-e33c-4735-b968-ce0f9a564d5c",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS] 1839년 바그너는 괴테의 파우스트을 처음 읽고 그 내용에 마음이 끌려 이를 소재로 해서 하나의 교향곡을 쓰려는 뜻을 갖는다. 이 시기 바그너는 1838년에 빛 독촉으로 산전수전을 다 [UNK] 상황이라 좌절과 실망에 가득했으며 메피스토펠레스를 만나는 파우스트의 심경에 공감했다고 한다. 또한 파리에서 아브네크의 지휘로 파리 음악원 관현악단이 연주하는 베토벤의 교향곡 9번을 듣고 깊은 감명을 받았는데, 이것이 이듬해 1월에 파우스트의 서곡으로 쓰여진 이 작품에 조금이라도 영향을 끼쳤으리라는 것은 의심할 여지가 없다. 여기의 라단조 조성의 경우에도 그의 전기에 적혀 있는 것처럼 단순한 정신적 피로나 실의가 반영된 것이 아니라 베토벤의 합창교향곡 조성의 영향을 받은 것을 볼 수 있다. 그렇게 교향곡 작곡을 1839년부터 40년에 걸쳐 파리에서 착수했으나 1악장을 쓴 뒤에 중단했다. 또한 작품의 완성과 동시에 그는 이 서곡 ( 1악장 ) 을 파리 음악원의 연주회에서 연주할 파트보까지 준비하였으나, 실제로는 이루어지지는 않았다. 결국 초연은 4년 반이 지난 후에 드레스덴에서 연주되었고 재연도 이루어졌지만, 이후에 그대로 방치되고 말았다. 그 사이에 그는 리엔치와 방황하는 네덜란드인을 완성하고 탄호이저에도 착수하는 등 분주한 시간을 보냈는데, 그런 바쁜 생활이 이 곡을 잊게 한 것이 아닌가 하는 의견도 있다. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(tokenized_input['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "da96bafc-79ce-41d5-b85c-3b987453c621",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm, trange\n",
    "import argparse\n",
    "import random\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from transformers import BertModel, BertPreTrainedModel, AdamW, TrainingArguments, get_linear_schedule_with_warmup\n",
    "\n",
    "torch.manual_seed(2021)\n",
    "torch.cuda.manual_seed(2021)\n",
    "np.random.seed(2021)\n",
    "random.seed(2021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cdfccbc3-a8d5-47bc-acb8-0ccf4505c5ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60407 5\n"
     ]
    }
   ],
   "source": [
    "sample_idx = np.random.choice(range(len(dataset['train'])),128)\n",
    "\n",
    "training_dataset = dataset['train'][sample_idx]\n",
    "\n",
    "print(len(dataset['train']),len(training_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "82791864-4653-46a4-96c0-802ee8399a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import (DataLoader, RandomSampler, TensorDataset)\n",
    "q_seqs = tokenizer(training_dataset['question'],padding='max_length',truncation=True,return_tensors='pt')\n",
    "p_seqs = tokenizer(training_dataset['context'],padding='max_length',truncation=True,return_tensors='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e785b722-031e-4f25-a056-fd2e480e70e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TensorDataset(p_seqs['input_ids'],p_seqs['attention_mask'],p_seqs['token_type_ids'],\n",
    "                             q_seqs['input_ids'],q_seqs['attention_mask'],q_seqs['token_type_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "88a710d8-5f17-4026-8b10-d0848b3314a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertEncoder(BertPreTrainedModel):\n",
    "    def __init__(self,config):\n",
    "        super(BertEncoder,self).__init__(config)\n",
    "        \n",
    "        self.bert = BertModel(config)\n",
    "        self.init_weights()\n",
    "        \n",
    "    def forward(self,input_ids,attention_mask=None,token_type_ids=None):\n",
    "        outputs = self.bert(input_ids,attention_mask=attention_mask,token_type_ids=token_type_ids)\n",
    "        pooled_output = outputs[1]\n",
    "        return pooled_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "14fd9629-d661-454d-b1a1-9b5615254ef9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertEncoder: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertEncoder from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertEncoder from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertEncoder: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertEncoder from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertEncoder from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU enabled\n"
     ]
    }
   ],
   "source": [
    "p_encoder = BertEncoder.from_pretrained(model_checkpoint)\n",
    "q_encoder = BertEncoder.from_pretrained(model_checkpoint)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    p_encoder.cuda()\n",
    "    q_encoder.cuda()\n",
    "    print('GPU enabled')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "039de497-e70c-43ba-9443-e906a04eac02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(args, dataset, p_model, q_model):\n",
    "    # DataLoader\n",
    "    train_sampler = RandomSampler(dataset)\n",
    "    train_dataloader = DataLoader(dataset, sampler = train_sampler, batch_size= args.per_device_train_batch_size)\n",
    "    \n",
    "    #Optimizer\n",
    "    \n",
    "    no_decay = ['bias','LayerNorm.weight']\n",
    "    optimizer_grouped_parameters = [\n",
    "        {'params':[p for n,p in p_model.named_parameters() if not any(nd in n for nd in no_decay)],'weight_decay':args.weight_decay},\n",
    "        {'params':[p for n,p in p_model.named_parameters() if any(nd in n for nd in no_decay)],'weight_decay':0.0},\n",
    "        {'params':[p for n,p in q_model.named_parameters() if not any(nd in n for nd in no_decay)],'weight_decay':args.weight_decay},\n",
    "        {'params':[p for n,p in q_model.named_parameters() if any(nd in n for nd in no_decay)],'weight_decay':0.0}\n",
    "    ]\n",
    "    optimizer = AdamW(optimizer_grouped_parameters,lr = args.learning_rate, eps=args.adam_epsilon)\n",
    "    t_total = len(train_dataloader) // args.gradient_accumulation_steps*args.num_train_epochs\n",
    "    scheduler = get_linear_schedule_with_warmup(optimizer,num_warmup_steps=args.warmup_steps,num_training_steps=t_total)\n",
    "    \n",
    "    #Bert training\n",
    "    global_step =0\n",
    "    p_model.zero_grad()\n",
    "    q_model.zero_grad()\n",
    "    \n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    train_iterator = trange(int(args.num_train_epochs),desc='Epoch')\n",
    "    for _ in train_iterator:\n",
    "        epoch_iterator = tqdm(train_dataloader,desc ='Iteration')\n",
    "        for step, batch in enumerate(epoch_iterator):\n",
    "            q_encoder.train()\n",
    "            p_encoder.train()\n",
    "            \n",
    "            if torch.cuda.is_available():\n",
    "                batch = tuple(t.cuda() for t in batch)\n",
    "                \n",
    "            p_inputs = {'input_ids':batch[0],\n",
    "                       'attention_mask':batch[1],\n",
    "                       'token_type_ids':batch[2]}\n",
    "            q_inputs = {'input_ids':batch[3],\n",
    "                       'attention_mask':batch[4],\n",
    "                       'token_type_ids':batch[5]}\n",
    "            \n",
    "            p_outputs = p_model(**p_inputs) #(batch_size,emb_dim)\n",
    "            q_outputs = q_model(**q_inputs) #(batch_size,emb_dim)\n",
    "            \n",
    "            #Calculate similarity score & loss\n",
    "            \n",
    "            sim_scores = torch.matmul(q_outputs, torch.transpose(p_outputs,0,1))\n",
    "            \n",
    "            # target\n",
    "            \n",
    "            targets = torch.arange(0,args.per_device_train_batch_size).long()\n",
    "            if torch.cuda.is_available():\n",
    "                targets=targets.to('cuda')\n",
    "                \n",
    "            sim_scores = F.log_softmax(sim_scores,dim=1)\n",
    "            loss = F.nll_loss(sim_scores,targets)\n",
    "            print(loss)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            q_model.zero_grad()\n",
    "            p_model.zero_grad()\n",
    "            global_step += 1\n",
    "            \n",
    "            torch.cuda.empty_cache()\n",
    "            \n",
    "        return p_model,q_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ab283ddb-2593-4ffa-aa49-feb2fb3d8068",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = TrainingArguments(\n",
    "        output_dir='dense_retireval',\n",
    "        evaluation_strategy='epoch',\n",
    "        learning_rate=2e-5,\n",
    "        per_device_train_batch_size=4,\n",
    "        per_device_eval_batch_size=4,\n",
    "        num_train_epochs=2,\n",
    "        weight_decay=0.01\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "dd4852f9-207c-4910-bcb2-b4ff8f5b5a59",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Epoch:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration:   0%|          | 0/32 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(30.8067, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration:   3%|▎         | 1/32 [00:00<00:15,  2.04it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.7890, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration:   6%|▋         | 2/32 [00:00<00:14,  2.13it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.4556, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration:   9%|▉         | 3/32 [00:01<00:13,  2.16it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.0117, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration:  12%|█▎        | 4/32 [00:01<00:12,  2.17it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.1795, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration:  16%|█▌        | 5/32 [00:02<00:12,  2.18it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.8373, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration:  19%|█▉        | 6/32 [00:02<00:11,  2.19it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.0509, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration:  22%|██▏       | 7/32 [00:03<00:11,  2.19it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.4032, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration:  25%|██▌       | 8/32 [00:03<00:10,  2.19it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.6181, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration:  28%|██▊       | 9/32 [00:04<00:10,  2.19it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.0241, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration:  31%|███▏      | 10/32 [00:04<00:10,  2.19it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.3806, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration:  34%|███▍      | 11/32 [00:05<00:09,  2.19it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.3743, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration:  38%|███▊      | 12/32 [00:05<00:09,  2.19it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.7644, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration:  41%|████      | 13/32 [00:05<00:08,  2.19it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.2583, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration:  44%|████▍     | 14/32 [00:06<00:08,  2.20it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.2649, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration:  47%|████▋     | 15/32 [00:06<00:07,  2.20it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.3480, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration:  50%|█████     | 16/32 [00:07<00:07,  2.20it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.3123, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration:  53%|█████▎    | 17/32 [00:07<00:06,  2.18it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.1898, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration:  56%|█████▋    | 18/32 [00:08<00:06,  2.18it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.9730, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration:  59%|█████▉    | 19/32 [00:08<00:05,  2.18it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.0165, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration:  62%|██████▎   | 20/32 [00:09<00:05,  2.19it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.6145, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration:  66%|██████▌   | 21/32 [00:09<00:05,  2.20it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.3497, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration:  69%|██████▉   | 22/32 [00:10<00:04,  2.19it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.6899, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration:  72%|███████▏  | 23/32 [00:10<00:04,  2.20it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.2989, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration:  75%|███████▌  | 24/32 [00:10<00:03,  2.20it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.5882, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration:  78%|███████▊  | 25/32 [00:11<00:03,  2.21it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.0624, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration:  81%|████████▏ | 26/32 [00:11<00:02,  2.20it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.3177, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration:  84%|████████▍ | 27/32 [00:12<00:02,  2.21it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.2516, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration:  88%|████████▊ | 28/32 [00:12<00:01,  2.21it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.5671, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration:  91%|█████████ | 29/32 [00:13<00:01,  2.21it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.0733, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration:  94%|█████████▍| 30/32 [00:13<00:00,  2.18it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.2258, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration:  97%|█████████▋| 31/32 [00:14<00:00,  2.17it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.9605, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration: 100%|██████████| 32/32 [00:14<00:00,  2.19it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n"
     ]
    }
   ],
   "source": [
    "p_encoder,q_encoder = train(args,train_dataset,p_encoder,q_encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6e46cb41-9db3-43de-9939-1c70cc49f8bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "유아인에게 타고난 배우라고 말한 드라마 밀회의 감독은? 화보 촬영을 위해 미국에 있을 때, 김희애의 연락을 통해 JTBC 드라마 《밀회》의 캐스팅을 제안받았다. 당시 영화 《베테랑》에 이미 캐스팅된 상태였으나, 유아인은 류승완 감독과 제작사의 양해를 얻어 《밀회》에 출연한다. 천재 피아니스트 ‘이선재’ 역할을 위해 피아니스트들의 영상을 보고 곡의 스피드와 건반 위치 등을 외워 실제 타건을 하며 촬영했다. 피아노 울림판을 수건으로 막고 타건을 하면, 그 후 대역 피아니스트의 소리를 덧입히는 방식이었다. 《밀회》는 작품성을 인정받고 숱한 화제를 낳으며 당시 종편으로서는 높은 시청률을 기록했다. 유아인은 섬세한 연기력을 선보여 순수함으로 시청자들을 매료시켰다는 호평을 얻었고, 특히 피아노 연주에 있어서 클래식 종사자들에게 인정을 받았다. 연출을 맡은 안판석 감독은 유아인에 대해 “느낌으로만 연기를 하는 게 아니고 감성을 지적으로 통제해 가면서 연기한다. 그 나이에”라며 “타고난 배우”라고 말했다. 유아인은 《밀회》를 통해 예술적인 면모를 구체화할 수 있어서 만족감을 느꼈다고 밝혔으며, 종영 후 자신의 페이스북 계정에 긴 소감글을 남겼다. 특히 ‘이선재’ 캐릭터를 배우 유아인이 가진 소년성의 엑기스로 생각하며, 2015년 10월 부산국제영화제 오픈토크에서는 본인이 가장 좋아하는 캐릭터로 꼽았다.\n"
     ]
    }
   ],
   "source": [
    "valid_corpus = list(set(example['context'] for example in dataset['validation']))[:10]\n",
    "sample_idx = random.choice(range(len(dataset['validation'])))\n",
    "query = dataset['validation'][sample_idx]['question']\n",
    "ground_truth = dataset['validation'][sample_idx]['context']\n",
    "print(query,ground_truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "cb759877-4e41-4ef0-a2a9-8e5dae6845dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not ground_truth in valid_corpus:\n",
    "    valid_corpus.append(ground_truth)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "dc585048-ff87-4739-bfc4-2848aae02604",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_cuda(batch):\n",
    "    return tuple(t.cuda() for t in batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8ec22bc9-acb8-476b-82df-95a9e5e4bab5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([11, 768]) torch.Size([1, 768])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    p_encoder.eval()\n",
    "    q_encoder.eval()\n",
    "    \n",
    "    q_seqs_val = tokenizer([query],padding='max_length',truncation=True,return_tensors='pt').to('cuda')\n",
    "    q_emb = q_encoder(**q_seqs_val).to('cpu')\n",
    "    p_embs = []\n",
    "    for p in valid_corpus:\n",
    "        p = tokenizer(p,padding='max_length',truncation=True,return_tensors='pt').to('cuda')\n",
    "        p_emb = p_encoder(**p).to('cpu').numpy()\n",
    "        p_embs.append(p_emb)\n",
    "        \n",
    "    p_embs = torch.Tensor(p_embs).squeeze()\n",
    "    print(p_embs.size(),q_emb.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c677c234-eaca-4a03-8300-cfc984692b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "dot_prod_scores = torch.matmul(q_emb,torch.transpose(p_embs,0,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "7e10aa32-f275-412c-b0a1-1f132c4ad35d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 11])\n"
     ]
    }
   ],
   "source": [
    "print(dot_prod_scores.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "46f4736f-eb94-41e7-83f1-cd7fdd185bd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[29.4267, 31.4995, 31.0922, 30.9991, 29.3170, 32.3554, 31.3094, 32.7454,\n",
      "         32.6979, 30.2796, 32.1270]])\n",
      "tensor([ 7,  8,  5, 10,  1,  6,  2,  3,  9,  0,  4])\n"
     ]
    }
   ],
   "source": [
    "rank= torch.argsort(dot_prod_scores,dim=1,descending=True).squeeze()\n",
    "print(dot_prod_scores)\n",
    "print(rank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "80783aa9-ff8c-47c5-a32d-70b5dd76d81d",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search query 유아인에게 타고난 배우라고 말한 드라마 밀회의 감독은? \n",
      "\n",
      "ground truth passage\n",
      "화보 촬영을 위해 미국에 있을 때, 김희애의 연락을 통해 JTBC 드라마 《밀회》의 캐스팅을 제안받았다. 당시 영화 《베테랑》에 이미 캐스팅된 상태였으나, 유아인은 류승완 감독과 제작사의 양해를 얻어 《밀회》에 출연한다. 천재 피아니스트 ‘이선재’ 역할을 위해 피아니스트들의 영상을 보고 곡의 스피드와 건반 위치 등을 외워 실제 타건을 하며 촬영했다. 피아노 울림판을 수건으로 막고 타건을 하면, 그 후 대역 피아니스트의 소리를 덧입히는 방식이었다. 《밀회》는 작품성을 인정받고 숱한 화제를 낳으며 당시 종편으로서는 높은 시청률을 기록했다. 유아인은 섬세한 연기력을 선보여 순수함으로 시청자들을 매료시켰다는 호평을 얻었고, 특히 피아노 연주에 있어서 클래식 종사자들에게 인정을 받았다. 연출을 맡은 안판석 감독은 유아인에 대해 “느낌으로만 연기를 하는 게 아니고 감성을 지적으로 통제해 가면서 연기한다. 그 나이에”라며 “타고난 배우”라고 말했다. 유아인은 《밀회》를 통해 예술적인 면모를 구체화할 수 있어서 만족감을 느꼈다고 밝혔으며, 종영 후 자신의 페이스북 계정에 긴 소감글을 남겼다. 특히 ‘이선재’ 캐릭터를 배우 유아인이 가진 소년성의 엑기스로 생각하며, 2015년 10월 부산국제영화제 오픈토크에서는 본인이 가장 좋아하는 캐릭터로 꼽았다. \n",
      "\n",
      "top-1 passage with score 32.7454\n",
      "이회창 후보의 친동생 이회성과 이 후보의 최측근 서정우 변호사 등으로 구성된 대선 비선조직인 부국팀이 병역문제로 대선자금이 잘 걷히지를 않자 국세청을 동원한 대선자금 모집을 이회창 후보에게 보고한후 1997년 10월 하순 부터 대선직전까지 국세청 차장 이석희와 선거 자금을 불법으로 모은 사건. 부국팀은 9월에 차수명 한나라당 재정위원장으로부터 기탁금 고액미납자 명단을 건네받아 미납기업들을 상대로 기탁금 납부를 독촉하였는데 이때 국세청과 한나라당이 대선자금 모금을 위해 조직적으로 공모한 사건이다. 또한 이 자금을 이석희 전 국세청 차장이 관리하던 차명계좌에서 사적으로 전용한 사실이 드러났다. 2003년 4월 8일 검찰은 23개기업으로부터 166억3천만원을 모금한 혐의로 이석희를 기소하였다. 이때 검찰은 이회창 당시 한나라당 총재가 모금하던 임채주 당시 국세청장에게 전화를 하여 격려한 사실을 확인하였다. 이석희 전 국세청 차장은 미국 도피중 2002년 2월 16일 미국 FBI에 체포되어 한국으로 송환되었다. 이회성은 1998년 구속되었다.\n",
      "top-2 passage with score 32.6979\n",
      "그러나 군사정권 출신과 일부 보수 세력에서는 그의 등장을 인정하기를 거부했다. 김영삼의 사생활이 본격적으로 도마에 오른 것은 1992년 민자당 대선후보 때였다. 그 해 2월 20일자 LA매일신문에 '김영삼 씨의, 숨겨둔 딸 가오리, 뉴욕에 거주하고 있다.'는 기사가 실린 것을 시작으로 국내외 언론에서 동시다발적인 보도가 나왔다. 이 과정에서 LA매일신문 발행인 손충무가 긴급 구속되기도 했다. 당시 국내에서는 'ys의 숨겨둔 딸 가오리 양'의 이야기가 널리 회자화됐다. 나중에는 의혹이 눈덩이처럼 커져 \"숨겨진 딸뿐만 아니라 아들도 있다더라\"는 소문도 나돌았다. 군사 정권 출신 인사들은 이를 호재삼아 김영삼을 비난하는 근거로 활용했다.\n",
      "top-3 passage with score 32.3554\n",
      "이런 집권당에서의 사면 논의에 대해 1997년 8월 31일, 97년 대선을 앞두고 당시 김대중 새정치국민회의 대통령 후보는 간담회에서 \"김영삼 대통령 임기중에 전두환 노태우를 사면하여 동서화합의 길이 열리도록 하겠다\"는 의견을 밝혔다. 그는 이어 \"그들(전두환 노태우)이 잘못을 반성하지 않는다고 우리도 똑같이 대응할 수는 없다\"고 밝혔다. 그리고 다음날인 9월 1일 SBS 대통령 후보와 함께라는 프로그램에서 김대중 총재는 전두환 노태우에 대한 용서론을 강조했다. 이렇게 김대중후보가 전두환 노태우 사면을 내세우자 경향신문은 \"화해의 정치인'부각 영남 끌어 안기6共(공)세력들도 포용 색깔론 차단 효과까지 ‘용서’광주여론도 한몫 국민회의 김대중(金大中(김대중))총재가 정치권의「뜨거운 감자\"라는 내용의 기사를 실었다. 그리고 10월 23일, 새정치국민회의 박정수 부총재는 국회 본회의 연설에서 \"김영삼대통령이 전두환 노태우를 사면하는 것이 바람직하고 김대중후보가 당선되면 대대적인 사면이 단행될 것\"이라고 밝혔다. 이날 김대중 후보를 대신해 대표 연설에 나선 새정치국민회의 박정수 부총재는 집권 정치 보복을 절대 하지 않겠다는 김대중후보의 약속을 거듭 강조하고 아무런 전제 조건을 달지 않은 채 전두환·노태우 前 대통령에 대한 사면을 촉구했다. 그에 대응하여 9월 1일 신한국당 대선후보인 이회창은 보수세력의 연합과 국민적인 지지를 얻고 김대중 후보의 전두환 노태우 사면론을 무력화시키기 위해 김영삼대통령에게 전두환 노태우 두 전직 대통령을 추석 전에 사면해 줘야 된다고 요구한다. 당시 김영삼 대통령은 이회창의 전두환 노태우 두 전직대통령 조기석방에 대해 \"국민적인 공감대가 형성돼야 된다\"며 이회창의 요구를 들어주지 않았다. 당시 정치권이 경쟁적으로 앞다투어 전두환 노태우 사면을 공약으로 내세우자 사회 각계에서도 개탄의 분위기가 쏱아졌다. 당시 김영삼대통령은 9월 12일, 당초 전두환 사면에 대해 \"국민적인 공감대가 형성돼야 한다\"며 이회창의 요구를 들어주지 않았으나 다시 말을 바꿔 대선 전에 사면을 할 것이라며 입장을 선회한다. 이렇게 이회창이 전두환 사면을 공약으로 내세우자 감옥에 있는 전두환이 이회창에게 \"고맙다\"며 \"우리 때문에 정치적 어려움을 겪는 것은 아니냐\" 화답할 만큼 매우 기뻐했던 것으로 밝혀졌다. 그에 대해 이회창 후보도 전두환의 화답에 \"고생 많으시다. 추석때 나오시기를 바랬는데 그렇게 되지 않아 아쉽다\"고 전두환측에게 화답한 것으로 밝혀졌다. 당시 한겨레에서는 이회창 신한국당 대표가 \"추석전 전두환 노태우 두분의 석방을 바랬는데 그렇게 되지 않아 아쉽게 됐다\"고 전두환 측근들에게 화답하였다고 보도했다. 그리고 이회창은 9월 24일, cbs와 경실련과의 간담회에서 전두환 노태우 사면에 대해 \"전직 대통령이 구금상태에 있는 것은 바람직하지 않고 대통합 차원에서 석방해 정상적인 생활을 영위토록 하는 것이 바람직하다\"며 전두환 노태우 사면론에 적극적으로 찬성한다. 이는 곧 경쟁자인 김대중의 전두환 노태우 사면론을 무력화하기 위한 것이었다. 이회창과 김대중이 전두환 노태우의 사면 복권 공약을 내세운 것에 대해 이인제도 경쟁적으로 전두환과 노태우를 사면 복권한다는 공약을 내세웠다 결국 이렇게 1997년 대선에서 이회창 김대중 이인제 3후보 모두가 전두환 노태우의 사면 복권을 경쟁적으로 대선 공약으로 내걸었던 것이다. 그러나 12월 18일 대선에서 이회창은 김대중후보에게 39만표차로 떨어져 낙선하고, 전두환과 노태우는 김대중이 대통령에 당선된 다음날인 1997년 12월 20일, 김영삼대통령과 김대중대통령 당선자와의 협의로 사면 복권되었다. 당시의 전두환 노태우 사면은 김영삼 대통령의 제안에 김대중대통령 당선자가 이것을 수용하는 형식으로 이뤄졌는데 김대중당선자는 12월 21일, 일산자택에서 \"이제는 국민 통합이 중요하다\"며 전두환 노태우 사면을 지지했다. 이런 사면에 대해 낙선한 이회창후보 측근도 \"이회창쪽에서도 추석전 조기사면을 요구한 만큼 김대중당선자도 사면을 주장했으니 당연한조치\"라고 평했고 낙선한 이인제후보쪽에서도 전두환 노태우 사면에 대해 \"이제는 국민대화합의 계기가 되어야 하고 매우 잘된 일\"이라고 평가했다. 12월 21일, 김대중당선자가 김영삼대통령과 협의에 의해 전두환 노태우를 사면한 것에 대해 외국 언론들은 용기있는 결정이라며 평가했다. 뉴욕타임스지는 김대중 당선자가 전두환 노태우의 사면에 동의한 것은 자신의 쓰라린 과거를 묻어둘 의사가 있음을 시시한 것이라고 평가했고 미국의 ABC방송은 김대중 당선자가 40년간에 걸친 고난의 정치역정을 용서로써 마무리 짓는 의미가 있다고 평가했다. ABC방송은 이어 김 당선자의 용서는 경제회생이라는 어려운 임무를 떠안게 된 새 지도자로서 정치적인 지지를 확보하기 위한 것이라고 논평했다. 워싱턴포스트 신문은 김 당선자의 이번 조치가 국가 화합과 지역감정 해소, 그리고 경제위기 극복에 큰 도움이 될 것이라고 보도했다. 뉴욕타임스는 \" IMF 경제위기를 극복하기 위한 정치적 화합책의 하나로 김대중(金大中(김대중))대통령당선자는 두 명의 전임 독재자들에 대한 사면에 동의했다. 김영삼대통령 측 대변인은 김대중당선자가 전두환 노태우 사면에 대해 동의했다고 밝혔으나 김대중 당선자측은 전두환 노태우 사면에 대해 우리가 그들(김영삼, 이회창 신한국당 대선후보, 전두환, 노태우)의 제안을 받아들인 것 뿐\"이라고 밝혀 사면에 대한 둘의 미묘한 신경전을 보도했다. 당시 사면에 대해 1997년 12월 22일자 동아일보에서도 \"전두환 노태우의 사면은 유력 대통령후보들이 모두 대화합을 명분으로 사면을 공약으로 내세움으로써 대선 후 사면은 기정사실화되어 있었다\"라고 보도했다.\n",
      "top-4 passage with score 32.1270\n",
      "화보 촬영을 위해 미국에 있을 때, 김희애의 연락을 통해 JTBC 드라마 《밀회》의 캐스팅을 제안받았다. 당시 영화 《베테랑》에 이미 캐스팅된 상태였으나, 유아인은 류승완 감독과 제작사의 양해를 얻어 《밀회》에 출연한다. 천재 피아니스트 ‘이선재’ 역할을 위해 피아니스트들의 영상을 보고 곡의 스피드와 건반 위치 등을 외워 실제 타건을 하며 촬영했다. 피아노 울림판을 수건으로 막고 타건을 하면, 그 후 대역 피아니스트의 소리를 덧입히는 방식이었다. 《밀회》는 작품성을 인정받고 숱한 화제를 낳으며 당시 종편으로서는 높은 시청률을 기록했다. 유아인은 섬세한 연기력을 선보여 순수함으로 시청자들을 매료시켰다는 호평을 얻었고, 특히 피아노 연주에 있어서 클래식 종사자들에게 인정을 받았다. 연출을 맡은 안판석 감독은 유아인에 대해 “느낌으로만 연기를 하는 게 아니고 감성을 지적으로 통제해 가면서 연기한다. 그 나이에”라며 “타고난 배우”라고 말했다. 유아인은 《밀회》를 통해 예술적인 면모를 구체화할 수 있어서 만족감을 느꼈다고 밝혔으며, 종영 후 자신의 페이스북 계정에 긴 소감글을 남겼다. 특히 ‘이선재’ 캐릭터를 배우 유아인이 가진 소년성의 엑기스로 생각하며, 2015년 10월 부산국제영화제 오픈토크에서는 본인이 가장 좋아하는 캐릭터로 꼽았다.\n",
      "top-5 passage with score 31.4995\n",
      "2007년 8월 인터뷰에서, 플레이스테이션 3용 바이오쇼크의 실현성에 대한 질문에 그 당시 켄 레빈은 \"플레이스테이션 3용 개발은 진행하지 않는다\"라고 했다. 그러나 2008년 5월 28일, 2K 게임즈는 2K 마린이 플레이스테이션 3용 바이오쇼크를 개발중이며 조던 토마스가 플레이스테이션 3 버전의 감독이라고 발표했고, 그것은 2008년 10월 17일에 발매되었다. 엑스박스 360 버전보다 그래픽이 향상되진 않았으나, 플레이스테이션 3 버전은 \"Horizontal Plus\"라 불리는 와이드스크린 옵션을 제공하는데, 그것은 360 버전 패치를 통해 소개됐던 컷신 동영상이 DVD 버전보다 더 높은 해상도를 갖게 된 것이었다. 플레이스테이션 3 버전만 지원하는 애드온 콘텐츠가 추가되었다. 그 중 하나는 \"서바이버 모드\"로, 적들이 더욱 강해지고, 부활 장치를 사용했을 때 공급받는 체력의 량이 줄어들며, 플레이어는 적에게 있어 더욱 \"창의적\"으로 접근해야 하며, 적은 량의 플라스미드에 의존해야 한다. 바이오쇼크는 또한 PS3 트로피와 플레이스테이션 홈을 지원한다. 데모는 2008년 10월 2일 플레이스테이션 스토어를 통해 공개됐다.\n",
      "top-6 passage with score 31.3094\n",
      "황비홍 밑에서 수련하던 임세영은 광주로 떠나 자신의 도장을 열게 되었다. 그곳에는 소림 무예를 전수하던 도장이 있었는데 그곳의 관장은 성정이 포악하여 자신의 도장 근처에 새로운 도장이 들어설 때마다 직접 찾아가 대련을 신청하여 이에 응하면 그곳의 사범을 반죽음을 만들어놓아 도장을 폐쇄시켜 도장이 들어설 수 없도록 하고 있었다. 임세영의 도장이 들어서자 역시 임세영의 도장에 찾아와 대련을 신청하였고 임세영은 좋은 말로 거절하였으나 끈질기게 요구하자 할 수 없이 대련을 하게 되었고 그곳의 관장은 임세영의 한 수에 나가떨어지고 말았다. 그러나 패배를 인정하지 않고 후일을 기약하며 돌아간 그는 남들 앞에서 허세를 부리며 임세영을 비난하였고 임세영은 자신을 뒤에서 욕하는 그를 호되게 비판하였다. 그러자 격분한 소림 무예 도장의 관장은 18반 병기 중 하나인 쌍극을 들고 임세영을 찾아갔으나 역시 임세영의 한 수에 나가떨어져 큰 부상을 입었다. 부상을 치료하기 위해 그는 수군 무예 교두인 황비홍을 찾아갔는데 황비홍이 보기에 예사 상처가 아니었기에 어떻게 이런 상처가 났느냐고 물어보았고 관장은 사실대로 말하였다. 그러자 황비홍은 임세영이 자신의 제자라며 죽지 않은 것을 다행으로 알라며 훈계하였다. 이에 소림 무예 도장의 관장은 간담이 서늘하여 다시는 얼씬거리지 않았다고 한다.\n",
      "top-7 passage with score 31.0922\n",
      "초등학교때부터 주 포지션이었던 외야수, 3루수는 물론 투수 겸 포수의 재능도 상당히 뛰어나 모든 포지션을 도맡았다. 나승현과 함께 광주제일고등학교의 원투펀치 에이스로 활약했으며 원래 내야수였다가 3학년때 포수로 전향하기도 했는데 팀 내에서 그 말고는 나승현의 공을 제대로 잡는 포수가 없었던게 가장 큰 이유였다. 투수로도 148km를 뿌리는 강속구 투수였을 정도로 어깨가 굉장히 좋았고 프로 스카우트들 사이에서는 어깨뿐만 아니라 공빼는 속도와 능력은 당장에 프로와서도 포수로서 최상급 수준이라고 평했을 정도로 인정을 받았다. 2005년 황금사자기 결승전에서 8이닝 동안 2안타 무실점으로 승리투수를 기록하여 광주제일고등학교의 우승에 큰 기여를 하였고 대회 우수투수상과 타점상을 받았다. 그 시절 우승을 이끈 대활약으로 지금까지 황금사자기가 낳은 최고의 스타로 불리고 있다. 같은 해 청소년 국가대표로 선발되어 제6회 아시아청소년야구선수권 대회에 주전 포수이자 주장으로 출전하였다. 그는 야구명문 광주제일고등학교의 주장이자 4번타자, 포수를 맡아 맹활약 하였으며, 2학년때에 이어서 2년 연속 청소년 대표팀에 선발되었다. 대한민국 내에서 이재원과 함께 저학년인 2학년때부터 청소년 대표로 뽑힌 야수로 주 포지션인 유격수, 3루수뿐만 아니라 투수, 포수, 2루수, 1루수까지 내야 모든 포지션을 볼 수 있는 만능 유망주로서 이름을 알렸다. 그 당시 동기인 류현진, 한기주, 나승현, 김현수, 이재원, 민병헌, 김문호, 최주환 등과 후배인 김광현등 쟁쟁한 대표팀 선수들 사이에서도 일본에서 가장 주의해야 할 한국 선수로 뽑혔으며, 청소년 대표팀에서도 주장과 4번타자를 맡았다. 2005년 청소년 야구대회에서 일본 에이스 스지우치를 상대로 유일한 타점을 올렸으며, 이 대회에서 15타수 6안타, 5타점, 타율 0.375을 기록했다. 대회가 끝나고 청소년 대표 베스트 10 포수로 선정되기도 하였다. 당시 광주일고 허세환 감독은 그가 알루미늄 배트를 쓰는 세대에 있었다면 전년도 1차 지명 대상자였던 최정, 박병호 그 이상이었을 것이라고 말해 화제를 모으기도 했다. 특이하게도 본인과 스타일이 정반대지만 고교시절 롤모델이자 우상으로 삼던 선수는 이치로였다. 2005년 드래프트에서는 광주지역에 계약금 10억 원의 대형신인 한기주가 있었고 같은 고등학교의 에이스 나승현도 있었기에 고졸 야수로는 가장 빠른 순번인 2차 드래프트 1라운드에 지명되었다.\n",
      "top-8 passage with score 30.9991\n",
      "태평양 북서부 살인 사건의 마지막은 7월 14일 일요일 시애틀 동쪽 20 마일(32 km) 떨어진 이사쿠아 소재 레이크 새머미시 주립 공원에서 2명의 여성 유괴사건이었다. 5명의 여성 목격자들은 팔걸이 붕대를 한 테니스 운동복을 입고 아마도 캐나다나 영국 같은 밝은 억양의 젊고 매력적인 남자에 관해 묘사했다. 자신을 '테드'라고 소개한 남자가 그들에게 탄색 혹은 갈색의 폭스바겐 비틀 자동차에서 보트를 꺼내는 걸 도와 달라고 요청했다. 4명은 거절했지만 한 사람은 그 남자와 함께 자동차까지 갔고, 보트가 없는 것을 보고 도망쳤다. 3명의 추가적인 목격자들은 그 남자가 킹 카운티 소년법정에서 보호관찰관로 일하는 23살의 제니스 앤 오트에게 접근하는 것을 보았는데, 보트 이야기를 하면서 그 남자와 함께 해변을 떠나는 것을 목격했다. 약 4시간 후에 컴퓨터 프로그래머가 되기 위해 공부하고 있던 19살 데니스 마리 나스런드가 피크닉을 가서 화장실에 가서 돌아오지 못했다. 번디는 스티븐 미쇼에게 말하기를 번디가 나스런드와 함께 돌아갔을 때 오트는 아직 살아 있었다고 했지만 나중에 번디는 루이스와의 인터뷰에서 처형 전날에 관해 언급하면서 그 사실을 부인했다.\n",
      "top-9 passage with score 30.2796\n",
      "미시시피 델타 블루스로 불리기도 하는 초기의 블루스는 컨트리 블루스 혹은 포크 블루스로 불리기도 한다. 클럽에서 대규모의 빅밴드와 함께 연주하던 스윙 재즈와는 달리, 대부분의 블루스 뮤지션들은 떠돌이 악사들 수준이었다. 어쿠스틱 기타나 하모니카가 악기의 전부였고 글을 읽거나 쓰기는 커녕, 악보조차도 제대로 볼 수 없는 문맹이 대부분이었다. 흑인이 대부분이어서 였다. 하지만, 음악이란 풍부한 자원을 공급할 수 있는 가능성을 가진 그들을 당시의 레코드 회사들이 그냥 지나치지는 않았다. 찰리 패튼(Charley Patton), 선 하우스(Son House), 로버트 존슨과 같은 뮤지션들이 하나 둘씩 레코딩을 시작했고, 백인들에게도 블루스의 존재가 조금씩 알려지기 시작했던 것이다.\n",
      "top-10 passage with score 29.4267\n",
      "쇼와 천황은 12월 31일에 열린 어전회의를 거쳐 과달카날에서 일본군의 철수를 명령했다. 일본군은 솔로몬 제도에서도 연합군의 공격으로 수세에 몰리고 있었지만 쇼와 천황과 대본영은 방어선의 축소를 반대했으며, 과달카날 탈환을 요구하며 나가노 오사미를 압박했다. 한편 일본군은 북방 전선에서도 수세에 몰리고 있었다. 1943년 5월 29일, 알류샨 열도의 애투 섬의 수비대가 전멸 당했으며 8월 이후로 미국군의 솔로몬 공세로 남방 전선도 차차 무너졌다. 7월에 무솔리니 정권이 무너진 이탈리아가 9월 8일에 연합군에 항복하고, 쿠르스크 전투에서 나치 독일이 소비에트 연방에 대패하면서 일본 제국과 함께 하는 추축 세력도 약해져갔다. 일본군 선전대는 알류산 열도에서의 수비대 전멸을 “천황 폐하를 위한 자기희생과 용기의 극치”라고 미화했지만 정작 쇼와 자신은 참모총장들에게 “왜 확실한 승리를 얻지 못했느냐”며 일갈했으며 미군의 고립 전략에 특별히 주의할 것을 주문했다. 또, 야마모토 이소로쿠의 국장을 치르고 사흘이 지난 뒤 애투 군도에서의 패배를 분석하는 자리에서 쇼와 천황은 “육군과 해군이 정말로 협력하고 있는지 의심스럽다. 귀군들은 (패배 원인이) 짙은 안개 때문이라는 등 갖은 변명들만 늘어놓고 있는데 그런 문제점들은 사전에 충분히 검토했어야 되는 것 아닌가?”라며 육군과 해군의 반목과 불통을 지적했다.\n",
      "top-11 passage with score 29.3170\n",
      "1982년에 수상 존 맥도날드와 다른 고위 정치가들은 태평양 스캔들에서 뇌물에 흔들려 \"캐나다 태평양 철도사\"(현존하는 동명의 회사와는 무관)의 휴 알렌과 연방 계약을 체결했고, 대양간 철도사와도 계약을 체결했다. 이 사건 때문에 보수당은 1873년에 물러났다. 새로 집권한 자유당소속 수상인 알렉산더 매캔지는 공공사업의 일환으로 일부구간의 건설을 시작했다. 선더베이와 위니펙을 잇는 구간의 준공은 1875년에 선언되었다. 공공예산의 부족으로 사업의 진전은 상당히 느렸다. 1878년 10월 16일에 존 맥도날드가 재집권하자 사업에 진척이 되기 시작했다. 맥도날드는 서쪽으로 종착점은 포트하디가 될것이고, 포트하디와 캠룹스사이의 구간은 프레이저 강과 톰슨 강을 따라 건설될 것이라고 하였다.\n"
     ]
    }
   ],
   "source": [
    "k = 11\n",
    "print('Search query',query,'\\n')\n",
    "print('ground truth passage')\n",
    "print(ground_truth,'\\n')\n",
    "\n",
    "for i in range(k):\n",
    "    print(\"top-%d passage with score %.4f\" % (i+1,dot_prod_scores.squeeze()[rank[i]]))\n",
    "    print(valid_corpus[rank[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46473404-4092-469a-957d-496aafa22129",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
