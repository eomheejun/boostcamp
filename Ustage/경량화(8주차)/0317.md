# Pruning

<a href="https://ibb.co/fqMGDHp"><img src="https://i.ibb.co/S5N7fBn/2021-03-17-21-59-13.png" alt="2021-03-17-21-59-13" border="0"></a>

위의 사진처럼 사람은 성장하면서 잘 않쓰이는 synapses를 잘라내게 되어 성인이 되면 어릴 때의 비해 평균적으로 절반 가까운 synapses를 가지게 된다. 딥러닝에서 마찬가지로 모델의 기능을 최대한 방해하지 않는 선에서 학습 후 불필요한 부분을 제거하는 방식으로, 가중치의 크기에 기반한제거, 어텐션 헤드 제거, 레이어 제거 등 여러 방법으로 불필요한 부분을 제거하여 모델을 압축한다.

<a href="https://ibb.co/QfZ8fLG"><img src="https://i.ibb.co/pxgWxcp/2021-03-17-22-01-50.png" alt="2021-03-17-22-01-50" border="0"></a>

학습이 끝난 뒤 pruning을 하게 되면 predict하는데 있어서 속도를 줄일 수 있게 된다. 반면 정보를 잃게 된다는 단점이 있다. 

<a href="https://ibb.co/WftzRvj"><img src="https://i.ibb.co/9Wt4dHS/2021-03-17-22-03-30.png" alt="2021-03-17-22-03-30" border="0"></a>

위와 같이 연결된 신경망에서 불필요한 부분을 제거하게 된다. 주로 weight 값이 0인 부분을 제거를 하게 되는데 (weight 가 0이면 불필요한 부분이라고 판단) 제거 하고 나면 오른쪽과 같은 그림을 가지게 되는데 그 숫자가 1/10의 크기로 줄게 되어(엄청나게 많이 제거) 실제로 나타나는 그림은 처음의 그림에서 굉장히 작은 갯수의 weight 들만 남게 된다. 다시말해 predict하는데 있어서 계산량이 적어져 속도가 빠르게 된다.

<a href="https://ibb.co/zfgG8pM"><img src="https://i.ibb.co/JkT5xV1/2021-03-17-22-05-59.png" alt="2021-03-17-22-05-59" border="0"></a>

왼쪽은 pruning 오른쪽은 dropout이다. 비슷해보이지만 내용은 다르다. 우선 pruning은 한번 제거하게 되면 복원이 안된다. 원본의 모델 모형을 불필요한 부분을 제거하면서 경량화를 시킨것이다. 반면 dropout은 overfit을 방지하기 위해 random하게 노드들을 껐다 켰다를 반복하게 되는 것이다. 다시 말해 원본 모델의 모형은 바뀌지 않게 된다는 차이점이 있다.

<a href="https://ibb.co/Vj0vNSG"><img src="https://i.ibb.co/Pms5Yhy/2021-03-17-22-08-06.png" alt="2021-03-17-22-08-06" border="0"></a>



# pruning의 종류

<a href="https://ibb.co/b2M1BLV"><img src="https://i.ibb.co/F0L6wJ1/2021-03-17-22-12-22.png" alt="2021-03-17-22-12-22" border="0"></a>

pruning의 종류는 크게 4가지로 나뉜다.

- 무엇을 prune 할 지
- 어떻게 prune 할 지
- 언제 prune할 지

- 얼마나 자주 prune 할 지

  

<a href="https://ibb.co/B6cFDyD"><img src="https://i.ibb.co/n16t272/2021-03-17-22-13-56.png" alt="2021-03-17-22-13-56" border="0"></a>

pruning의 첫 번째 종류인 무엇을 prune할지에서 Unstructured Pruning과 Structured Pruning의 차이를 알아보자. unstructured pruning은 특정 가중치에 대해 하는 게 아니라 그냥 neuron이나 layer 등 아무거나 연결성이 낮아보이면 삭제하는 것이다. 이러면 sparse해지기 쉽고 hardware에서의 optimize가 어렵다. 반대로 structured pruning은 특정 filter를 삭제한다. filter전체, 혹은 채널 ,shape의 일부를 삭제할 수 있다. 



pruning의 목적은 모델의 기능을 최대한 방해하면 안되는 선에서 불필요한 부분을 삭제해야 하지만 위와 같은 경우에는 모델의 기능이 저하될 수 있다. 

<a href="https://ibb.co/1mjHTy4"><img src="https://i.ibb.co/hmwpVQT/2021-03-17-22-17-45.png" alt="2021-03-17-22-17-45" border="0"></a>

따라서 iterative pruning을 사용해 학습후 pruning하고 끝내는것이 아니라 학습 -> pruning -> 재학습의 과정을 반복적으로 돌면서 파라미터를 조금씩 삭제한다.



