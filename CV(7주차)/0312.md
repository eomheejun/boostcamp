# Keypoint 예측	

```
# Hyper-paramter Settings
data_root = '/content/BodyLandmarkData/data'
log_dir   = '/content/BodyLandmarkData/log'

epochs = 3
batch_size = 8
lr = 1e-3
input_size = 320
```

```
# Dataset
import torch
from torchvision import transforms
from torch.utils.data import Dataset, DataLoader

import os
import cv2
import json
import numpy as np
from glob import glob

class BodyLandmarkDataset(Dataset):
  def __init__(self, data_root, is_Train=True, input_size=224, transform=None):
    super(BodyLandmarkDataset, self).__init__()

    self.img_list = self._load_img_list(data_root, is_Train)

    self.len = len(self.img_list)
    self.input_size = input_size
    self.hm_size = input_size//4
    self.transform = transform
    
    self.n_landmarks = 22
    self.sigma = 1.5

  def __getitem__(self, index):
    img_path = self.img_list[index]
    anno_path = img_path.replace('.jpg', '.json')
    
    # Image Loading
    img = cv2.imread(img_path)
    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
    img = img/255.
    
    org_size = img.shape[:2]

    if self.transform:
      img = self.transform(img)

    # Ground Truth
    heatmap = self._get_heatmaps_from_json(anno_path, org_size)

    return img, heatmap

  def __len__(self):
    return self.len
  
  def _load_img_list(self, data_root, is_Train):
    # Change the name of directory which has inconsistent naming rule.
    full_img_list = glob(os.path.join(data_root, 'single', '*', '*color.jpg'))
    
    # ID < 400 for Training
    # 400 < ID for Validation
    if is_Train:
      return [path for path in full_img_list if (self._load_img_ID(path) < 400)]
    else:
      return [path for path in full_img_list if (400 < self._load_img_ID(path))]

  def _load_img_ID(self, path):
    return int(path.split(os.sep)[-2].strip('id_1'))

  def _get_heatmaps_from_json(self, anno_path, org_size):
    # Parse point annotation
    with open(anno_path, 'r') as json_file:
      pts = json.load(json_file)
    pts = np.array([(pt['pt_x'], pt['pt_y']) for pt in pts['DataList'][0]['coordinates']])

    pts[:,0] = pts[:,0] / org_size[1] * self.hm_size
    pts[:,1] = pts[:,1] / org_size[0] * self.hm_size

    heatmap = np.zeros((self.n_landmarks, self.hm_size, self.hm_size), dtype=np.float32)
    for i, pt in enumerate(pts):
      heatmap[i] = self._draw_labelmap(heatmap[i], org_size, pt, self.sigma)
    
    return heatmap

  def _draw_labelmap(self, heatmap, org_size, pt, sigma):
    # Draw a 2D gaussian
    # Adopted from https://github.com/anewell/pose-hg-train/blob/master/src/pypose/draw.py
    H, W = heatmap.shape[:2]

    # Check that any part of the gaussian is in-bounds
    ul = [int(pt[0] - 3 * sigma), int(pt[1] - 3 * sigma)]
    br = [int(pt[0] + 3 * sigma + 1), int(pt[1] + 3 * sigma + 1)]
    if (ul[0] >= heatmap.shape[1] or ul[1] >= heatmap.shape[0] or
            br[0] < 0 or br[1] < 0):
        # If not, just return the image as is
        return heatmap, 0

    # Generate gaussian
    size = 6 * sigma + 1
    x = np.arange(0, size, 1, float)
    y = x[:, np.newaxis]
    x0 = y0 = size // 2
    # The gaussian is not normalized, we want the center value to equal 1

    '''======================================================='''
    '''======================== TO DO ========================'''
    g = np.exp(- ((x - x0) ** 2 + (y - y0) ** 2) / (2 * sigma ** 2))
    '''======================== TO DO ========================'''
    '''======================================================='''

    # Usable gaussian range
    g_x = max(0, -ul[0]), min(br[0], heatmap.shape[1]) - ul[0]
    g_y = max(0, -ul[1]), min(br[1], heatmap.shape[0]) - ul[1]
    # Image range
    heatmap_x = max(0, ul[0]), min(br[0], heatmap.shape[1])
    heatmap_y = max(0, ul[1]), min(br[1], heatmap.shape[0])

    heatmap[heatmap_y[0]:heatmap_y[1], heatmap_x[0]:heatmap_x[1]] = g[g_y[0]:g_y[1], g_x[0]:g_x[1]]
    return heatmap
    
    return anno_path
```

<a href="https://ibb.co/rt8DmNs"><img src="https://i.ibb.co/26VGyHN/2021-03-13-22-57-30.png" alt="2021-03-13-22-57-30" border="0"></a><br 

todo부분에 가우시안 heatmap의 공식이 들어갔다.

```
# Dataset and Data Loader
MEAN = [0.485, 0.456, 0.406]
STD  = [0.229, 0.224, 0.225]

transform = transforms.Compose([
    transforms.ToTensor(),
    transforms.Resize((input_size, input_size)),
    transforms.Normalize(mean=MEAN,
                          std=STD)
])

train_dataset = BodyLandmarkDataset(data_root, is_Train=True, input_size=input_size, transform=transform)
train_loader = DataLoader(train_dataset, batch_size=batch_size, pin_memory=True, shuffle=True)

valid_dataset = BodyLandmarkDataset(data_root, is_Train=False, input_size=input_size, transform=transform)
valid_loader = DataLoader(valid_dataset, batch_size=batch_size, pin_memory=True, shuffle=False)
```

```
# Misc

class AverageMeter(object):
  """Computes and stores the average and current value"""
  def __init__(self):
      self.reset()

  def reset(self):
    self.val = 0
    self.avg = 0
    self.sum = 0
    self.count = 0

  def update(self, val, n=1):
    self.val = val
    self.sum += val * n
    self.count += n
    self.avg = self.sum / self.count
```

```
# Main
os.makedirs(log_dir, exist_ok=True)

with open(os.path.join(log_dir, 'train_log.csv'), 'w') as log:
  for epoch in range(epochs):
    train_loss, valid_loss = AverageMeter(), AverageMeter()

    # Training
    for iter, (img, hm_gt) in enumerate(train_loader):
      '''================================================================'''
      '''======================== TO DO Main (1) ========================'''
      # optimizer에 저장된 미분값을 0으로 초기화
      optimizer.zero_grad()

      # GPU 연산을 위해 이미지와 정답 tensor를 GPU로 보내기 (필요한 경우, 변수의 type도 수정해주세요)
      img, hm_gt = img.float().cuda(), hm_gt.float().cuda()

      # 모델에 이미지 forward
      pred_logit = model(img)

      # loss 값 계산
      loss = 0
      for pred in pred_logit:
        loss += criterion(pred, hm_gt)

      # Backpropagation
      loss.backward()
      optimizer.step()
      '''======================== TO DO Main (1) ========================'''
      '''================================================================'''

      # Log Update
      train_loss.update(loss.item(), len(img))
      print("\rEpoch [%3d/%3d] | Iter [%3d/%3d] | Train Loss %.4f" % (epoch+1, epochs, iter+1, len(train_loader), train_loss.avg), end='')

    # Validation
    for iter, (img, hm_gt) in enumerate(valid_loader):
      '''================================================================'''
      '''======================== TO DO Main (2) ========================'''
      # GPU 연산을 위해 이미지와 정답 tensor를 GPU로 보내기 (필요한 경우, 변수의 type도 수정해주세요)
      img, hm_gt = img.float().cuda(), hm_gt.float().cuda()

      # 모델에 이미지 forward (gradient 계산 X)
      with torch.no_grad():
        pred_logit = model(img)

      # loss 값 계산
      loss = 0
      for pred in pred_logit:
        loss += criterion(pred, hm_gt)
      '''======================== TO DO Main (2) ========================'''
      '''================================================================'''

      # Log Update
      valid_loss.update(loss.item(), len(img))
 
    print("\nEpoch [%3d/%3d] | Valid Loss %.4f" % (epoch+1, epochs, valid_loss.avg))
    
    # Log Writing
    log.write('%d,%.4f,%.4f\n'%(epoch, train_loss.avg, valid_loss.avg))
```

